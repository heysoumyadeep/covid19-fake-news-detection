{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\"\"\"\n",
    "    Used for data manipulation and analysis\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\"\"\"\n",
    "Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python. \n",
    "\"\"\"\n",
    "\n",
    "import itertools\n",
    "\"\"\" \n",
    "    Itertools is a module in python, it is used to iterate over data structures that can be stepped over using a \n",
    "    for-loop. Such data structures are also known as iterables.\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\"\"\"\n",
    "    classification_report builds a text report showing the main classification metrics. \n",
    "    confusion_matrix computes confusion matrix to evaluate the accuracy of a classification.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "    accuracy_score used to calculate the accuracy of either the faction or count of correct prediction in Python Scikit learn.\n",
    "    Compute the F1 score, also known as balanced F-score or F-measure.\n",
    "    \n",
    "    The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. \n",
    "    The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
    "    The best value is 1 and the worst value is 0.\n",
    "    \n",
    "    The recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. \n",
    "    The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "    The best value is 1 and the worst value is 0.\n",
    "    \n",
    "    The F1 score can be interpreted as a harmonic mean of the precision and recall, where an F1 score reaches \n",
    "    its best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal.\n",
    "    \n",
    "    This metric is calculated as:\n",
    "    F1 Score = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "\"\"\"\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Read an Excel file into a pandas DataFrame\n",
    "\"\"\"\n",
    "df=pd.read_excel('../data/Constraint_Train.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The CDC currently reports 99031 deaths. In gen...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>States reported 1121 deaths a small rise from ...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>#IndiaFightsCorona: We have 1524 #COVID testin...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Populous states can generate large case counts...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              tweet label\n",
       "0   1  The CDC currently reports 99031 deaths. In gen...  real\n",
       "1   2  States reported 1121 deaths a small rise from ...  real\n",
       "2   3  Politically Correct Woman (Almost) Uses Pandem...  fake\n",
       "3   4  #IndiaFightsCorona: We have 1524 #COVID testin...  real\n",
       "4   5  Populous states can generate large case counts...  real"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Prints top 5 rows of excel file\n",
    "\"\"\"\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Drops the rows containing Null values\n",
    "\"\"\"\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Drops the independent features, and stores it into X\n",
    "\"\"\"\n",
    "X=df.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['label']\n",
    "\"\"\"\n",
    "    Drops the dependent features, and stores it into y\n",
    "\"\"\"\n",
    "type(y)\n",
    "arr=[]\n",
    "for i in y:\n",
    "    if i=='real':\n",
    "        arr.append([1])\n",
    "    else:\n",
    "        arr.append([0])\n",
    "\"\"\"\n",
    "    Here, we are converting 'real' and 'fake' to '1' and '0' respectively.\n",
    "\"\"\"\n",
    "y=arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\"\"\"\n",
    "    It can be used across a range of tasks but has a particular focus\n",
    "    on training and inference of deep neural networks.\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\"\"\"\n",
    "    embedding is a dense vector of floating point values\n",
    "    (the length of the vector is a parameter that is specified).\n",
    "\"\"\"\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\"\"\"\n",
    "    To make each input length fixed\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "\"\"\"\n",
    "    A Sequential model is appropriate for a plain stack of layers \n",
    "    where each layer has exactly one input tensor and one output tensor.\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "\"\"\"\n",
    "    One-hot encodes a text into a list of word indexes of size n.\n",
    "    It returns a list of encoded integers each corresponding to a word \n",
    "    (or token) in the given input string.\n",
    "\n",
    "\"\"\"\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\"\"\"\n",
    "    Imports LSTM Classificatio model from Keras\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "    Dense implements the operation:\n",
    "    output = activation(dot(input, kernel) + bias). \n",
    "    These are all attributes of Dense. \n",
    "\"\"\"\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Specify the vocabulary size, to be used later.\n",
    "\"\"\"\n",
    "voc_size=5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Copies the tuple X into variable messages.\n",
    "\"\"\"\n",
    "messages=X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Reset the index, or a level of messages dataframe \n",
    "    to get a new order of arrangement.\n",
    "\"\"\"\n",
    "messages.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\abhis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\"\"\"\n",
    "    It is a suite of libraries and programs for symbolic and statistical natural language \n",
    "    processing (NLP) for English written in the Python programming language. \n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "    A regular expression (or RE) specifies a set of strings that matches it. The functions \n",
    "    in this module is to check if a particular string matches a given regular expression.\n",
    "\"\"\"\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Preprocessing is done here.\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\"\"\"\n",
    "    Algorithm to for removing the commoner morphological \n",
    "    and inflexional endings from words in English. \n",
    "\"\"\"\n",
    "\n",
    "ps = PorterStemmer()\n",
    "corpus = []\n",
    "\n",
    "\"\"\"\n",
    "        In this loop, the words in the dataframe 'messages' is splitted and then joined \n",
    "        after adding the blank spaces between the words and stored in tuple variable 'review'.\n",
    "        Followed by this, all the stopwords are removed.\n",
    "\"\"\"\n",
    "for i in range(0, len(messages)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', messages['tweet'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    One-hot encodes a text into a list of word indexes of size n.\n",
    "    It returns a list of encoded integers each corresponding to a word \n",
    "    (or token) in the given input string.\n",
    "\"\"\"\n",
    "onehot_repr=[one_hot(words,voc_size)for words in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0 4401 ... 1784 1190 2621]\n",
      " [   0    0    0 ... 2794  361 3689]\n",
      " [   0    0    0 ... 1047 3815 1823]\n",
      " ...\n",
      " [   0    0    0 ... 4615  470 1215]\n",
      " [   0    0    0 ... 4041 4408 3124]\n",
      " [4499 2883 1339 ...  106 2179 4259]]\n"
     ]
    }
   ],
   "source": [
    "sent_length=20\n",
    "\"\"\"\n",
    "    Maximum Sentence Length in the tweet.\n",
    "\"\"\"\n",
    "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
    "\"\"\"\n",
    "    Here we are padding before each sequence where the maximum length = sent_length\n",
    "\"\"\"\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 20, 40)            200000    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                9344      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               4224      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 223,937\n",
      "Trainable params: 223,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Creating the model\n",
    "embedding_vector_features=40\n",
    "model=Sequential()\n",
    "\"\"\"\n",
    "    Sequential model is a linear stack of layers.\n",
    "\"\"\"\n",
    "model.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\n",
    "\"\"\"\n",
    "    We're adding different features to the sequential model\n",
    "\"\"\"\n",
    "model.add(LSTM(32, input_shape=(10, 64)))\n",
    "\"\"\"\n",
    "    It is the number of LSTM memory units connected to each input of the series.\n",
    "\"\"\"\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(1,activation='relu'))\n",
    "\"\"\"\n",
    "    Here we're are using the layer activation funtion 'sigmoid'.\n",
    "\"\"\"\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\"\"\"\n",
    "    Binary cross entropy compares each of the predicted probabilities to \n",
    "    actual class output which can be either 0 or 1, and use it as a loss funtion.\n",
    "    \n",
    "    Adam optimizer involves a combination of two gradient descent methodologies: \n",
    "        - Momentum.\n",
    "        - Root Mean Square Propagation (RMSP). \n",
    "\"\"\"\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    We're converting the datatype from list to array.\n",
    "\"\"\"\n",
    "X_final=embedded_docs\n",
    "\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "    NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays \n",
    "    and matrices, along with a large collection of high-level mathematical functions to operate on these arrays.\n",
    "\"\"\"\n",
    "y_final=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\"\"\"\n",
    "    Here we are spliting the dataset, where the test_size is 1/3 of all data and we are initializing the\n",
    "    internal randoms number generator as 42.\n",
    "\"\"\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "68/68 [==============================] - 6s 36ms/step - loss: 0.9065 - accuracy: 0.6564 - val_loss: 0.3409 - val_accuracy: 0.8386\n",
      "Epoch 2/25\n",
      "68/68 [==============================] - 2s 24ms/step - loss: 0.2497 - accuracy: 0.9168 - val_loss: 0.2796 - val_accuracy: 0.8948\n",
      "Epoch 3/25\n",
      "68/68 [==============================] - 2s 25ms/step - loss: 0.1791 - accuracy: 0.9637 - val_loss: 0.4300 - val_accuracy: 0.8976\n",
      "Epoch 4/25\n",
      "68/68 [==============================] - 2s 25ms/step - loss: 0.1033 - accuracy: 0.9844 - val_loss: 0.6387 - val_accuracy: 0.9000\n",
      "Epoch 5/25\n",
      "68/68 [==============================] - 2s 26ms/step - loss: 0.0731 - accuracy: 0.9914 - val_loss: 0.7012 - val_accuracy: 0.8929\n",
      "Epoch 6/25\n",
      "68/68 [==============================] - 2s 26ms/step - loss: 0.0636 - accuracy: 0.9958 - val_loss: 0.8311 - val_accuracy: 0.8962\n",
      "Epoch 7/25\n",
      "68/68 [==============================] - 2s 26ms/step - loss: 0.0617 - accuracy: 0.9958 - val_loss: 0.8793 - val_accuracy: 0.8952\n",
      "Epoch 8/25\n",
      "68/68 [==============================] - 2s 26ms/step - loss: 0.0609 - accuracy: 0.9960 - val_loss: 0.8950 - val_accuracy: 0.8957\n",
      "Epoch 9/25\n",
      "68/68 [==============================] - 2s 24ms/step - loss: 0.0606 - accuracy: 0.9960 - val_loss: 0.9051 - val_accuracy: 0.8948\n",
      "Epoch 10/25\n",
      "68/68 [==============================] - 2s 26ms/step - loss: 0.0605 - accuracy: 0.9960 - val_loss: 0.9152 - val_accuracy: 0.8957\n",
      "Epoch 11/25\n",
      "68/68 [==============================] - 2s 25ms/step - loss: 0.0605 - accuracy: 0.9960 - val_loss: 0.9276 - val_accuracy: 0.8962\n",
      "Epoch 12/25\n",
      "68/68 [==============================] - 2s 23ms/step - loss: 0.0605 - accuracy: 0.9960 - val_loss: 0.9425 - val_accuracy: 0.8966\n",
      "Epoch 13/25\n",
      "68/68 [==============================] - 2s 26ms/step - loss: 0.0605 - accuracy: 0.9960 - val_loss: 0.9306 - val_accuracy: 0.8929\n",
      "Epoch 14/25\n",
      "68/68 [==============================] - 2s 26ms/step - loss: 0.0605 - accuracy: 0.9960 - val_loss: 0.9306 - val_accuracy: 0.8929\n",
      "Epoch 15/25\n",
      "68/68 [==============================] - 2s 26ms/step - loss: 0.0605 - accuracy: 0.9960 - val_loss: 0.9306 - val_accuracy: 0.8929\n",
      "Epoch 16/25\n",
      "68/68 [==============================] - 2s 27ms/step - loss: 0.0605 - accuracy: 0.9960 - val_loss: 0.9306 - val_accuracy: 0.8929\n",
      "Epoch 17/25\n",
      "68/68 [==============================] - 2s 25ms/step - loss: 0.0605 - accuracy: 0.9960 - val_loss: 0.9306 - val_accuracy: 0.8929\n",
      "Epoch 18/25\n",
      "68/68 [==============================] - 2s 26ms/step - loss: 0.0605 - accuracy: 0.9960 - val_loss: 0.9306 - val_accuracy: 0.8929\n",
      "Epoch 19/25\n",
      "68/68 [==============================] - 2s 24ms/step - loss: 0.0605 - accuracy: 0.9960 - val_loss: 0.9306 - val_accuracy: 0.8929\n",
      "Epoch 20/25\n",
      "68/68 [==============================] - 2s 25ms/step - loss: 0.0605 - accuracy: 0.9960 - val_loss: 0.9306 - val_accuracy: 0.8929\n",
      "Epoch 21/25\n",
      "68/68 [==============================] - 2s 23ms/step - loss: 0.0605 - accuracy: 0.9960 - val_loss: 0.9306 - val_accuracy: 0.8929\n",
      "Epoch 22/25\n",
      "68/68 [==============================] - 2s 24ms/step - loss: 0.0605 - accuracy: 0.9960 - val_loss: 0.9306 - val_accuracy: 0.8929\n",
      "Epoch 23/25\n",
      "68/68 [==============================] - 2s 25ms/step - loss: 0.0605 - accuracy: 0.9960 - val_loss: 0.9306 - val_accuracy: 0.8929\n",
      "Epoch 24/25\n",
      "68/68 [==============================] - 2s 26ms/step - loss: 0.0605 - accuracy: 0.9960 - val_loss: 0.9306 - val_accuracy: 0.8929\n",
      "Epoch 25/25\n",
      "68/68 [==============================] - 2s 27ms/step - loss: 0.0605 - accuracy: 0.9960 - val_loss: 0.9306 - val_accuracy: 0.8929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18e306a9c08>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "    Here we are training the model where epochs is the number of times we iterate over the training set \n",
    "    and the number of training examples utilized in one iteration.\n",
    "\"\"\"\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=25,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\"\"\"\n",
    "    Dropout is a technique used to prevent a model from overfitting.\n",
    "\"\"\"\n",
    "model.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    The model is fitted with trained data, and then used to make prediction.\n",
    "\"\"\"\n",
    "y_pred=(model.predict(X_test) >= 0.5).astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    to plot a sklearn confusion matrix(cm)\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    \"\"\"\n",
    "        Accuracy (all correct / all) = (TP + TN) / (TP + TN + FP + FN)\n",
    "    \"\"\"\n",
    "    \n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('YlOrRd') \n",
    "    \"\"\" \n",
    "        To select the colour theme of the confusion matrix\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    \"\"\"\n",
    "        To create a figure with the given width, height in inches.\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    \"\"\"\n",
    "       To display data as an image, i.e., on a 2D regular raster.\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    \"\"\"\n",
    "       To display a title and colorbar on the axes.\n",
    "    \"\"\"\n",
    "    \n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "        \n",
    "    \"\"\"\n",
    "        To put the labels on the confusion matrix, with or without rotation.\n",
    "    \"\"\"\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \"\"\"\n",
    "        To normalize the confusion matrix by slicing and adding a new axis.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    \"\"\"\n",
    "        To calculate the threshold by finding the maximum value in confusion matrix.\n",
    "    \"\"\"\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    \"\"\"\n",
    "        To display the values in the confusion matrix with different colours and precision.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \"\"\"\n",
    "        This automatically adjusts subplot params so that the subplot(s) fits in to the figure area. \n",
    "    \"\"\"\n",
    "    \n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \"\"\"\n",
    "        To plot the the labels on their respective axes.\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "        To show the confusion matix on screen.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def print_metrices(y_pred,y_test):\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred,))\n",
    "    print(\"Accuracy : \",accuracy_score(y_pred,y_test))\n",
    "    print(\"Precison : \",precision_score(y_pred,y_test, average = 'weighted'))\n",
    "    print(\"Recall : \",recall_score(y_pred,y_test,  average = 'weighted'))\n",
    "    print(\"F1 : \",f1_score(y_pred,y_test,  average = 'weighted'))\n",
    "    \"\"\"\n",
    "        Here, we are printing the confusion matrix, its accuracy, precision, recall and F1 score.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM\n",
      "val:\n",
      "[[ 875  129]\n",
      " [  98 1017]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.89      1004\n",
      "           1       0.89      0.91      0.90      1115\n",
      "\n",
      "    accuracy                           0.89      2119\n",
      "   macro avg       0.89      0.89      0.89      2119\n",
      "weighted avg       0.89      0.89      0.89      2119\n",
      "\n",
      "Accuracy :  0.8928739971684757\n",
      "Precison :  0.8934678641113514\n",
      "Recall :  0.8928739971684757\n",
      "F1 :  0.8929794935847963\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVAAAAEmCAYAAAA0k8gFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZxWZf3/8dd7ZkBAVBCUFDQ3XPm5hUpWau6a+5ZLKkqpZaZpaZnlUpaW39CyNM1ySc00TSVzySWXQAVExch9ASWRRUQEEfj8/jjX4M04M9xzmOHc99zv5+NxHnOfc677nM+Ze+ZzX9d1zrmOIgIzM2u7uqIDMDOrVk6gZmY5OYGameXkBGpmlpMTqJlZTk6gZmY5OYF2AEndJd0paaakm5diO0dIurc9Y1sWJH1B0vMdsN12+b12BpJek7Rz0XHUuppOoJIOlzRa0vuSJkv6h6TPt8OmDwL6AX0i4uC8G4mI6yNi13aIp0NJCknrNc5HxCMRsUEH7KrV36ukcyT9qYUYPy/p3yn5Tpf0mKStJJ2ZPv/3Jc2VtKBk/rmS43tbUkPJ9hokTZFU8RdSN/18rP3UbAKVdCpwMfBTsn/KNYHfAvu2w+Y/DbwQEfPbYVv2sVy/V0krAiOAXwMrA/2Bc4EPI+KnEdEzInoCJwAjG+cjYpOSzbwL7FEyvycwYymOxTqDiKi5CVgJeB84uJUyy5El2LfSdDGwXFq3AzAJOA2YAkwGjknrzgXmAR+lfQwDzgH+VLLttYAAGtL8UOAVYBbwKnBEyfJHS963LfAkMDP93LZk3UPAj4HH0nbuBfq2cGyN8Z9eEv9+ZEnhBWA6cGZJ+a2BkWRJZDJwKdA1rXs4HcvsdLxfbtx+Wr9u2t6WaX51YCqwQwuxbZSO5V3gOWCfln6vzbx3sd9zyfLBwLtl/F0s9vsuWR7AWcDNJctuAX6Q/Qu1uL1mjyWtuxr4DfD39Hk9DqzbyraOBF4HpqX9vgbsnPPz6U32hfIO2ZfACGBA0f+X1TgVHkAhBw27A/NJCayFMucBo4BVgVWAfwM/Tut2SO8/D+iSEs8HQO+0frF/5Gbm10p/1A3A8sB7wAZp3WrAJun1on9osprTjPSP1AAclub7pPUPAS8D6wPd0/wFLRxbY/w/SvF/Lf0z3QCsAGwCzAXWSeU/AwxJ+10LmACcUrK9ANZrsv1JJfNfS+/pAdwDXNRCXF2Al4Azga7AjmTJZYPmfo/NvL/Z9cCKZInnGrJaZO8W3r/o991keQCDgLeBXml6Oy2LnMdyNdkXy9bp93o98OcWtrUxWfLbjuyL/Zfp82tMoG39fPoAB6bPYwXgZuBvRf9fVuNUq034PsDUaL0peARwXkRMiYh3yGpAR5as/yit/ygi7iL7A8/b77cQGCSpe0RMjojnminzJeDFiLguIuZHxI3Af4G9S8r8MSJeiIg5wF+AzVvZ50fA+RHxEfBnoC9wSUTMSvt/DtgUICLGRMSotN/XgN8B25d7cBFxJfAiWS1rNbIaVHOGAD3JEv+8iHiArHZ0WLn7amH/7wGfJ0skVwLvSLpDUr82bGYucCdZDe5Q4I60rCXlHMutEfFE+ju8npY/r4OAERHxcER8CPyQ7G+m8fja9PlExLSI+GtEfBARs4DzWytvLavVBDoN6Ft6UqAZq5M1mRq9npYt2kaTBPwB2T9Mm0TEbLJ/yhOAyZL+LmnDMuJpjKl/yfz/2hDPtIhYkF7PST/fLlk/p/H9ktaXNELS/yS9R9Zv3LeVbTfnSrIa269TEmjO6sDEiFhYsqzpMeYSERMiYmhEDEhxrE7WLdMW1wJHpenaJZQt51jK/bxWByY2zqS/mWmN8239fCT1kPQ7Sa+n8g8DvSTVL+GYrIlaTaAjyWoP+7VS5i2ykxaN1kzL8phN1lxq9KnSlRFxT0TsQlY7+y9ZsllSPI0xvZkzpra4jCyugRGxIlmzVOW+WVJPsmR1FXCOpJVbKPoWsIak0r/Ldj/GiPgvWRN6UBvf+gjZZ9QPeHQJZdvzWCYDazTOSOpB1opq1NbP5zSy1tI2qfx2jZvOEVtNq8kEGhEzyfr/fiNpv/SN3EXSHpJ+nordCJwlaRVJfVP5Zi+RKcM4YDtJa0paCfh+4wpJ/STtI2l54EOyroAFzWzjLmD9dOlVg6Qvk/WNjcgZU1usQNZP+36qHX+9yfq3gXVaef8lwJiI+CrZSZPLWyj3ONmXzenp89iBrIviz22ItU5St5JpOUkbSjpN0gAASWuQNaVHtWG7WWdnFs8+6XVr2uNYGt0C7JUuxepK1vde+r/b1s9nBbIWxrvpy+zsHDEZNZpAASLil8CpZGdX3yFrIn0T+Fsq8hNgNPAM8CwwNi3Ls6/7gJvStsaweNKrI6sRvEV2UmF74BvNbGMasFcqO43sDPpeETE1T0xt9B3gcLKTIFeSHUupc4BrJL0r6ZDSFZL2JTtpd0JadCqwpaQjmu4kIuYB+5Cd6JlKdlnZUanGWK7DyJJD4/Ryinsb4HFJs8kS53iy32WbRMRzLfRRNy3XHseyaJ/AiWQn+SaTnTycVFKkrZ/PxWQnGqeS/S7ubmtMltGSv0jNzKw5NVsDNTNbWk6gZmY5OYGameXkBGpmllNrF5JXlV6qj0+pS9FhWA49t2h6eatVg9de/x9Tp87Mfe3oelo+Pmj2ir1PmsyH90TE7nn31VE6TQL9lLrwh4YBRYdhOWw76oqiQ7AcBg85bqne/wELOP4T94Y07xxeaPXON0l/ILvMb0pEDErLVia7pGstssFXDomIGZJEdm1y4xgWQyNibHrP0WSXNgL8JCKuaW2/bsKbWSFEloDKmcpwNdn1xqW+B9wfEQOB+9M8ZNfmDkzTcWR3clFyU8E2ZIO8nC2pd2s7dQI1s0KIrAlczrQkEfEw2Y0opfYlG4GL9HO/kuXXRmYU2TgAqwG7AfdFxPSImAHcxyeT8mI6TRPezKpPG2pwfSWNLpm/IiKW1PfTLyImA0TEZEmrpuX9KRmcheyurv6tLG+RE6iZFaYNCXRqRAxup902d+IrWlneIjfhzawQasOU09upaU76OSUtn0TJ6FbAALKxKFpa3iInUDMrTDueRGrOHcDR6fXRwO0ly49SZggwMzX17wF2ldQ7nTzaNS1rkZvwZlaY9qrBSbqR7FEyfSVNIjubfgHwF0nDgDeAxie53kV2CdNLZJcxHQMQEdMl/ZjseWOQPXGi6YmpxTiBmlkhGi9jag8R0dJjX3ZqpmyQDQ/Y3Hb+APyh3P06gZpZIRovY6pm1R6/mVWxaj8J4wRqZoVxAjUzy6E9+0CL4gRqZoVxAjUzy8E1UDOzpVBfdABLyQnUzArhGqiZ2VJwAjUzy8E1UDOzpeAEamaWkxOomVkOvhfezCwn94GamS0FJ1Azs5ycQM3McljK5x1VBCdQMyuMa6BmZjk5gZqZ5SCgvtw2fKtPZy+OE6iZFaZOZWZGJ1Azs48JUJWfRXICNbPCVHn+dAI1s+Ko3CZ8hXICNbNiyE14M7NcBNTXuQZqZpZLlVdAnUDNrDhuwpuZ5eQEamaWgxQ+C29mlleda6BmZvmUfStnhXICNbNC+FZOM7Ol4ARqZpaH3IQ3M8vNNVAzsxz8TCQzs6Xg60Btqa32rWPod+whEMHs8c/z0lfPYJN/XEP9CssD0GWVPswa/QzPH/R1VtxuGzb86+V8+NpEAKb97V4mnX9pkeHXrGO/diEj7hrJqqv0Yvy4qwH47vcu484R/6Zr1y6su87q/PH3Z9Cr1wrMm/cRx3/j/xg95nnq6uq45JffZIfttyj2ACpAfZU/FKnKw69+XVfvx2onHsUzQ/Zj3BZ7ovp6+h6yF+N3PIynt9qHp7fah1mPP8X0v92z6D3vPfrkonVOnsUZetTu3D3i54st22WnwYwf90eeGfsH1h+4Bj+78AYArrxqBADPPvVH7vvHRZx2+mUsXLhwmcdcSaSP70Za0rTkbenbkp6TNF7SjZK6SVpb0uOSXpR0k6Suqexyaf6ltH6tvMfgBFoB1NBAXfduUF9PXfduzJs8ZdG6up7Ls9IOn2X67f8sMEJrznZf2IyVe6+w2LJdd9mKhoasYTdkm42Z9OY7APxnwuvs9MUtAVh11d706tWT0WOeX7YBVyCVObW6Dak/8C1gcEQMAuqBQ4ELgeERMRCYAQxLbxkGzIiI9YDhqVwuTqAFm/fW27w1/Pd85uWH2eqNkSx4bxYz//noovV99tuFmQ+OZMGs9xctW2HIFmw2+k42uuMqum88sIiwrQx/uPou9thtawA223Rdbr/zMebPn8+rr05mzNjnmThxyhK20PlJ5U1laAC6S2oAegCTgR2BW9L6a4D90ut90zxp/U5SvusBOiyBSvqWpAmSrm9h/VBJNd/+rO+1IivvvTNj1v8ioz+9LXXL96Dv4fsuWt/3kL1556Y7F83Pfuo5xqy3PU8P3pvJv72WDW++rIiwbQnO/9l1NDTUc8ThuwBw7NA9GDBgFQYPOZ5TTruUbT87iIaG+oKjLFp5zfclNeEj4k3gIuANssQ5ExgDvBsR81OxSUD/9Lo/MDG9d34q3yfPEXRkDfQbwJ4RcUQH7qPq9drpc8x9bRLzp04n5s9n+t/uYcUhWVOvYeVe9NxqU2bc9eCi8gtmvc/C2R8A8O7d/0JdGmjo07uQ2K1511x7NyPuGsn1155FY8WmoaGB4Rd9k3Gjr+L2W8/n3XffZ+B6AwqOtFgiG0yknAnoK2l0yXTcou1IvclqlWsDqwPLA3s0s8vGTNxcbTPX5QAdchZe0uXAOsAdkv5EdnDdgTnAMRHxfJPyXwLOAvYmO7jLgTXT6lMi4rGOiLMSfPjGW6ywzebUde/GwjlzWemL2/L+mGcB6HPgHsy460Hiw3mLynfp15eP3p4KQM/Bm6K6OuZPm1FI7PZJd9/zOBdedCP/uv8SevTotmj5Bx/MJSJYfvnu3PfP0TQ01LPxxmsVF2glENSVX4WbGhGDW1i3M/BqRLwDIOlWYFugl6SGVMscALyVyk8C1gAmpSb/SsD0PIfQIQk0Ik6QtDvwRWAe8H8RMV/SzsBPgQMby0raHziVrLY6Q9INZB2/j0paE7gH2Kgj4qwE7z/5NNNuvZtNn7gd5i/g/XH/4e3f3wRA30P24s1f/G6x8n0O2INPHX84MX8+C+d8yAtfObmIsA047Cvn8dDD45g6dSYD1j6Ic390DD/7+fV8+OFH7LLHaUB2Iuny35zGlCkz2O1Lp1NXJ/r378t1fzyz4Ogrg/JV/Jp6AxgiqQdZJW0nYDTwIHAQ8GfgaOD2VP6OND8yrX8gInIFopzvW/KGpdeAwWQ1z18BA8mqyV0iYkNJQ4HvArOAXSPivfS+KXz8TQGwCrBhRMxqZh/HAccB9KPhM7d2+XSHHIt1rG1nX1V0CJbD4CHHMXrM87lvJtq0a9e4a5V+ZZVd461JY1qpgSLpXODLwHzgKeCrZH2dfwZWTsu+EhEfSuoGXAdsQVbzPDQiXslzDMviQvofAw9GxP7pequHSta9QtbUX5/sGwOyftnPRsScJW04Iq4ArgDYsK5bdd/SYFZjBKidRlSOiLOBs5ssfgXYupmyc4GD22O/y+IyppWAN9ProU3WvQ4cAFwraZO07F7gm40FJG3e0QGaWQEEqitvqlTLIrSfAz+T9BjZBa6LSSeUjgBulrQu6YJYSc9I+g9wwjKI0cwK0I7XgRaiw5rwEbFWejmVrIne6Idp/dXA1en1U8DGJWW+3FFxmVmFkFBDBWfHMngwETMrTM4bgCqGE6iZFSI7iVR0FEvHCdTMiuMaqJlZDnIN1Mwst/a6DrQoTqBmVpgqb8E7gZpZQYQvYzIzy0O4Bmpmlo/kPlAzs7x8Ft7MLCffiWRmloeo+sdaOoGaWSEE1NW7Bmpm1na+E8nMbCm4D9TMLB/XQM3M8pDvhTczy8V3IpmZ5SUhn4U3M8vHfaBmZjm5D9TMLI8Kf2RxOZxAzawQ2UPlqjuDOoGaWXHcB2pmloMA10DNzHIQ4Ed6mJnl1Fmb8JJWbO2NEfFe+4djZjVD6tRN+OeAIKtoN2qcD2DNDozLzGpBZ02gEbHGsgzEzGpQlTfhywpf0qGSzkyvB0j6TMeGZWadXuNZ+HKmCrXEBCrpUuCLwJFp0QfA5R0ZlJnVgMaz8OVMFaqcs/DbRsSWkp4CiIjpkrp2cFxmVgsqNzeWpZwE+pGkOrITR0jqAyzs0KjMrDZUcPO8HOX0gf4G+CuwiqRzgUeBCzs0KjPr/FRm/2cFJ9kl1kAj4lpJY4Cd06KDI2J8x4ZlZjWhFs7CA/XAR8C8NrzHzKx17VQDldRL0i2S/itpgqTPSlpZ0n2SXkw/e6eykvQrSS9JekbSlrnDLyOwHwA3AqsDA4AbJH0/7w7NzIBsPNAGlTWV4RLg7ojYENgMmAB8D7g/IgYC96d5gD2AgWk6Drgs7yGUcxLpK8BnIuIDAEnnA2OAn+XdqZlZdh1oO2wmu+18O2AoQETMA+ZJ2hfYIRW7BngIOAPYF7g2IgIYlWqvq0XE5Lbuu5zwX2fxRNsAvNLWHZmZfUL7NOHXAd4B/ijpKUm/l7Q80K8xKaafq6by/YGJJe+flJa1WWuDiQwnu3TpA+A5Sfek+V3JzsSbmS2d8s+w95U0umT+ioi4Ir1uALYEToqIxyVdwsfN9eY0t9MoN5BSrTXhG8+0Pwf8vWT5qDw7MjNbTNua8FMjYnAL6yYBkyLi8TR/C1kCfbuxaS5pNWBKSfnSsT4GAG+1JfRGrQ0mclWeDZqZlad9rvGMiP9Jmihpg4h4HtgJ+E+ajgYuSD9vT2+5A/impD8D2wAz8/R/QhknkSStC5wPbAx0Kwl6/Tw7NDMD2u0kUnIScH26zfwV4Ji09b9IGga8ARycyt4F7Am8RNZFeUzenZZzFv5q4CfARWSn/4/Bt3KaWXtop4FCImIc0FwTf6dmygZwYnvst5z83yMi7kk7fjkiziIbncnMLL9OMJxdOTXQDyUJeFnSCcCbfHw5gJlZflV+X2M5CfTbQE/gW2R9oSsBx3ZkUGZWA2rhscYllwbM4uNBlc3Mll5nTaCSbqOVi0sj4oAOiSinnluuw7ajrys6DMvhXB1edAiWw1u8vvQb6cRN+EuXWRRmVntU2Y/rKEdrF9LfvywDMbMapE6aQM3MOpSoiWcimZl1jCqvgZbdhStpuY4MxMxqkMqcKlQ5I9JvLelZ4MU0v5mkX3d4ZGbW+UnlTRWqnBror4C9gGkAEfE0vpXTzJaWgHqVN1WocvpA6yLidS3+LbCgg+Ixs1pSubmxLOUk0ImStgZCUj3ZsFEvdGxYZtb5VXbzvBzlJNCvkzXj1wTeBv6ZlpmZLZ3qzp9l3Qs/BTh0GcRiZrVEdP4aqKQraeae+Ig4rkMiMrPa0YnvhW/0z5LX3YD9WfyRoGZm+XT2GmhE3FQ6L+k64L4Oi8jMakMtjAfajLWBT7d3IGZWe6q8AlpWH+gMPu4DrQOm0/pD683MylPlGbTVBJqehbQZ2XOQABamJ9qZmS296s6frZ8DS8nytohYkCYnTzNrHyrziZwV3E9azkUET0jassMjMbPaU+WjMbX2TKSGiJgPfB74mqSXgdlkhxMR4aRqZkungmuX5WitD/QJYEtgv2UUi5nVkk5+J5IAIuLlZRSLmdWa6s6frSbQVSSd2tLKiPhlB8RjZrWkEzfh64GeVP13hJlVrCrPLq0l0MkRcd4yi8TMakst9IGamXWMyr7GsxytJdCdllkUZlabqjt/tpxAI2L6sgzEzGpMjY7GZGbWPjpxH6iZWcdyAjUzy8kJ1MwsD4Gq+6FITqBmVgwB9U6gZmY5uAZqZpZflfeBVnf6N7Pq1XgdaDuNSC+pXtJTkkak+bUlPS7pRUk3Seqali+X5l9K69fKewhOoGZWkNSEL2cqz8nAhJL5C4HhETEQmAEMS8uHATMiYj1geCqXixOomRVHKm9a4mY0APgS8Ps0L2BH4JZU5Bo+Hhx+3zRPWr9TKt9m7gM1s2IIqKsvt3RfSaNL5q+IiCtK5i8GTgdWSPN9gHfTY4kAJgH90+v+wESAiJgvaWYqP7Wth+AEamYFadNoTFMjYnCzW5H2AqZExBhJO3y88U+IMta1iROomRWnfc7Cfw7YR9KeQDdgRbIaaa+Sh2MOAN5K5ScBawCTJDUAKwG5Bk9yH6iZFacdTiJFxPcjYkBErAUcCjwQEUcADwIHpWJHA7en13ekedL6ByIiVw3UCdTMitE4In07nERqwRnAqZJeIuvjvCotvwrok5afCnwv7w7chDezgrT/iPQR8RDwUHr9CrB1M2XmAge3x/6cQM2sOOWfha9ITqBmVoxO/lA5M7MOtFT9mxXBCdTMilNX3eexqzv6TuiSS25k0KBD2GSTQ7j44hsAGDfueYYMGcrmmx/O4MFH8sQT4wuOsvbsc9VP+c7b/+brz97Z7Pr6rl048M/DOenFexk26i+s9OnsppfuK/fiqAeu5fuzxrLHr3+4qHzXnstz/FN/WzR9951R7Db8zGVyLBWlY8/Cdzgn0AoyfvxLXHnlbTzxxLU8/fQNjBjxKC+++Aann/4rzj77a4wbdwPnnXc8p5/+q6JDrTnjrr6VP+3+1RbXbzHsYObOeI9fD9yVUcOvZucLvwPA/Lkf8uAPL+He7/x8sfLz3p/N77bYb9H07utvMuHWezv0GCpOx1/G1OGcQCvIhAmvMWTI/6NHj240NDSw/fZbctttDyKJ996bDcDMme+z+uqrFBxp7XnjkdHMmT6zxfUb7LsjT19zGwD/ueUe1tnpswB89MEcJj42hvlzP2zxvSuv92mWX7UPbzwyusUynZOgvr68qUK5D7SCDBq0Lj/4wW+ZNu1dunfvxl13PcbgwRtx8cWnsdtu3+Q737mEhQsX8u9//6HoUK2JFfv3Y+bEyQDEggXMnTmL7n16M2fajCW+d9Bhe/HcTXd1dIiVqYJrl+Wo+BqopKslHbTkktVvo43W5owzjmKXXU5k991PYrPNBtLQUM9ll93C8OGnMnHi3xk+/FSGDftx0aFaU80lgjLvDhx06J6Mv/Hv7RxQFVC7jwe6zC3TyJSp3N9GBRg2bD/Gjr2ehx++kpVXXomBA9fkmmtGcMABOwJw8ME788QTzxUcpTX13qT/sdIaqwGg+nq6rbQCc6a/u8T39dt0A+oa6pk8tkY/U/eBtk7SWpImSPotMBY4UtJISWMl3SypZyr3I0lPShov6Yq8A5xWuylTskFh3njjf9x66wMcdthurL76KvzrX2MAeOCBJxk4cI0iQ7RkqxOPYKsTjwDghTseYLOj9wdg44N249UHRpW1jUGH7VWbtc9GVZ5Al1Uf6AbAMcCPgFuBnSNitqQzyG7mPw+4NCLOA5B0HbAX0Pw1I4mk44DjANZc81MdF/0ydOCBpzNt2ky6dGngN785g969V+TKK8/i5JMvYv78BXTr1pUrrvhB0WHWnANu+D/W2mFrevTtzbcn/ouHzv41fTdch4mPjQVg7FW3sP91v+CkF+9lzvSZ3HLotxe99+RX72e5FXtS37ULG+63M9fteixTJ7wMwCaH7MH1ex5XyDFVhCq/DlQ5R3EqfwfZA5sejIi108CnV5ONxwfQFRgZEcMkHUg2onQPYGXg1xFxgaSrgRERcUvTbZcaPHjjGD36uo45COtQ5+rwokPI5bA7L+emA05i4UcfFR1KIX7H67wVc3NXDwcPWi2evPXoJRcE6ja4cExLAyoXaVnVQGennwLui4jDSldK6gb8FhgcERMlnUM2MKpZxbpx7xOKDqG6te2RHhVpWdefRwGfk7QegKQektbn42Q5NfWJ1sRZdzNTmVNlWqbXgUbEO5KGAjdKWi4tPisiXpB0JfAs8Brw5LKMy8yKUNkniMrR4Qk0Il4DBpXMPwBs1Uy5s4Czmlk+tAPDM7MiVflVjb4TycwK5BqomVk+bsKbmeUggar7LLwTqJkVxzVQM7O8nEDNzHKQz8KbmeXmJryZWV5OoGZmbSehKr8X3gnUzArkGqiZWT4+iWRmlkdlj7RUDidQMyuOz8KbmeXkJryZWV6ugZqZtZ1U9Y/0cAI1swK5Bmpmlo9PIpmZ5SGW/XMt25cTqJkVxzVQM7OcnEDNzPKo/kd6VHcHhJlVOZU5tbIFaQ1JD0qaIOk5SSen5StLuk/Si+ln77Rckn4l6SVJz0jaMm/0TqBmVgylEenLmVo3HzgtIjYChgAnStoY+B5wf0QMBO5P8wB7AAPTdBxwWd5DcAI1s+JI5U2tiIjJETE2vZ4FTAD6A/sC16Ri1wD7pdf7AtdGZhTQS9JqecJ3AjWzApXdhO8raXTJdFyzW5PWArYAHgf6RcRkyJIssGoq1h+YWPK2SWlZm/kkkpkVp/zBRKZGxOBWNyX1BP4KnBIR76nlmmtzK6LcQEq5BmpmBWm3PlAkdSFLntdHxK1p8duNTfP0c0paPglYo+TtA4C38hyBE6iZFaiuzKllyqqaVwETIuKXJavuAI5Or48Gbi9ZflQ6Gz8EmNnY1G8rN+HNrBiivS6k/xxwJPCspHFp2ZnABcBfJA0D3gAOTuvuAvYEXgI+AI7Ju2MnUDMriNplQOWIeJSWLxbdqZnyAZy41DvGCdTMCuVbOc3M8vG98GZmeXg4OzOz/Kp8MBEnUDMrjpvwZmY5lHGfe6VzAjWzArkP1MwsH9dAzczycgI1M8uh+h/p4QRqZsVph1s5i+QEamYFWfLzjiqdE6iZFccnkczMchBuwpuZ5ecaqJlZDj4Lb2aWn/tAzczyqP7h7JSNbl/9JL0DvF50HB2kLzC16CAsl8782X06IlbJ+2ZJd5P9fsoxNSJ2z7uvjtJpEmhnJmn0kp6JbZXJn13nVt31ZzOzAjmBmpnl5ARaHa4oOgDLzZ9dJ+Y+UDOznFwDNTPLyQnUzCwnJ1Azs5ycQM3McnICrRLSJ28alqp8LLAaIWkjSdtJVT5yhn2C74WvApIU6XIJSZsCCyNifEQsLF1nlSd98R0JrAoslDQyIhYUHJa1E1/GVEUknQQcArwAbAZ8ISLmFBuVLeoXaX8AAAaKSURBVImkrsBZQG/gZuAxJ9HOwU3AKiHpi8DewI5kCfR9YG7J+uoeF6yTKf08ImIe8BNgBvBl4HNuzncOroFWqKZNc0kbA1sCawNfAPaKiHmS9omIO4qK0z6pSZfLzmRfdOOBWWQ10X7ADYCb81XOCbQCSeoSER+l18cC7wJvADcCb0fE59O6o4AjgMMiYnpR8VrzJJ0G7Af8F1iO7LbOx4AfAOsDl0fEv4uL0JaWm/AVRtL6wPmSVkuLBgJvRsRo4HvA+pJOlHQBcCpwmpNn5ZG0C/DFiPgCWdP9/5GdTPoc8FOyGukrxUVo7cEJtPKsSlZbOUlSX6AeWAUgIv4KHA10BWYDh0TE+KICtY810wc9iewzPJas62VvoA9wHrB9RPw8Iv63jMO0dubLmCpEY79ZRDwqKYB9gW+TJc9VJK0KzAdejIh/FBmrLa5Jn+fWZE9GmBYRUySdAAyPiEmSxpL1f/6nwHCtHTmBFizVXBQRCxuXRcRjkuYCQ4EdyM68DwHWBXpL2jMi3i4gXGtGSfL8FnAgWT/nQEnHAxOB6yVdTNYfur8/u87DCbR4y0fE+wDpH24lsgvlL5I0h6yp3g34UUS8J6m7r/2sDM3UPPcn+8K7ElgIvBsRl6bndW0KHB4RrxYVr7U/n4UvkKR9gH0jYpikU8j+AX8IXAo8HRFHShoEnEzWp/YTsuTqD61gTZLn8WR913XANGAvYL+ImCtpx4h4wHeMdU5OoAWR1Ae4iSw5zidLnMcB3wK2AQL4KCK+LGkjYLqbfpVH0peAg4BLgN+RtSgGpXXHAV8CvhIRs4qL0jqKE2hBJK1AdlvfTLIEeibZRfI/i4jPpibh3cCdEXF0cZFaSyT1B0YCD0XEUZKOJEuYrwJvAccAR0fEswWGaR3IlzEVJNVI7if7h3sxIhqfaT8y/VwXuAA4u4DwrAwR8SZwCrC7pP0i4jqyazxXBHqS1TydPDsxn0Qq1l+AscClkqYB/wC2kPRHYCdgx4h4rcD4bAki4lZJ84CfpjvIbgZOLDouWzbchK8AkrYk6w89E3gU6E92HaHP2FYJSXuQ3ap5SrrhwWqAE2iFkLQZ8ADw/Yjwo3CrULp98+WI8C2aNcIJtIKkS5bmRMTLRcdiZkvmBGpmlpPPwpuZ5eQEamaWkxOomVlOTqBmZjk5gZqZ5eQEWmMkLZA0TtJ4STdL6rEU29pB0oj0eh9J32ulbC9J38ixj3Mkfafc5U3KXC3poDbsay1JHuHfyuYEWnvmRMTmacSgecAJpSuVafPfRUTcEREXtFKkF9DmBGpWyZxAa9sjwHqp5jVB0m/J7s1fQ9KukkZKGptqqj0BJO0u6b+SHgUOaNyQpKGSLk2v+0m6TdLTadqWbGCUdVPt9xep3HclPSnpGUnnlmzrB5Kel/RPYIMlHYSkr6XtPC3pr01q1TtLekTSC5L2SuXrJf2iZN/HL+0v0mqTE2iNktQA7AE0jha0AXBtRGxBNgr+WcDOEbElMBo4VVI3stHW9yZ7Nv2nWtj8r4B/RcRmZA9Ue47siaIvp9rvdyXtSvbE0a2BzYHPSNpO0meAQ4EtyBL0VmUczq0RsVXa3wRgWMm6tYDtyUa9ujwdwzBgZkRslbb/NUlrl7Efs8V4NKba013SuPT6EeAqYHXg9YgYlZYPATYGHksPm+xKNszehsCrEfEigKQ/kQ0C3dSOwFEAEbEAmCmpd5Myu6bpqTTfkyyhrgDcFhEfpH3cUcYxDZL0E7Jugp7APSXr/pKeN/WipFfSMewKbFrSP7pS2vcLZezLbBEn0NozJyI2L12QkuTs0kXAfRFxWJNym5ONlN8eRDZ49O+a7OOUHPu4muwRGk9LGkr2XKJGTbcVad8nRURpokXSWm3cr9U4N+GtOaOAz0laD0BSD0nrA/8F1pa0bip3WAvvvx/4enpvvaQVgVlktctG9wDHlvSt9lf26OaHgf0ldU+j9u9dRrwrAJMldQGOaLLuYEl1KeZ1gOfTvr+eyiNpfUnLl7Efs8W4BmqfEBHvpJrcjZKWS4vPiogX0nN+/i5pKtnYpYOa2cTJwBWShgELgK9HxEhJj6XLhP6R+kE3AkamGvD7ZCO4j5V0EzCO7Pnqj5QR8g+Bx1P5Z1k8UT8P/IvseewnpAe9/Z6sb3Sssp2/Q/bIYbM28WhMZmY5uQlvZpaTE6iZWU5OoGZmOTmBmpnl5ARqZpaTE6iZWU5OoGZmOf1/KD9Z916t5+kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('LSTM')\n",
    "print ('val:')\n",
    "print_metrices(y_pred,y_test)\n",
    "\"\"\"\n",
    "    Transform the data from the excel sheet which are not under 'label' \n",
    "    column and apply predict with the final estimator.\n",
    "\n",
    "    This will be used later to print additional informations, like data types and memory used.\n",
    "\"\"\"\n",
    "create_confusion_matrix(confusion_matrix(y_test,y_pred),target_names=['fake','real'], normalize = False, \\\n",
    "                      title = 'Confusion matix of LSTM on data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
