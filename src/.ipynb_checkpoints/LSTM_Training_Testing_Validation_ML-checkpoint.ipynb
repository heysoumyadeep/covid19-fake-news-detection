{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\"\"\"\n",
    "    Used for data manipulation and analysis\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\"\"\"\n",
    "Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python. \n",
    "\"\"\"\n",
    "\n",
    "import itertools\n",
    "\"\"\" \n",
    "    Itertools is a module in python, it is used to iterate over data structures that can be stepped over using a \n",
    "    for-loop. Such data structures are also known as iterables.\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\"\"\"\n",
    "    classification_report builds a text report showing the main classification metrics. \n",
    "    confusion_matrix computes confusion matrix to evaluate the accuracy of a classification.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "    accuracy_score used to calculate the accuracy of either the faction or count of correct prediction in Python Scikit learn.\n",
    "    Compute the F1 score, also known as balanced F-score or F-measure.\n",
    "    \n",
    "    The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. \n",
    "    The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
    "    The best value is 1 and the worst value is 0.\n",
    "    \n",
    "    The recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. \n",
    "    The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "    The best value is 1 and the worst value is 0.\n",
    "    \n",
    "    The F1 score can be interpreted as a harmonic mean of the precision and recall, where an F1 score reaches \n",
    "    its best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal.\n",
    "    \n",
    "    This metric is calculated as:\n",
    "    F1 Score = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "\"\"\"\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Read an Excel file into a pandas DataFrame\n",
    "\"\"\"\n",
    "df=pd.read_excel('../data/Constraint_Train.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>The CDC currently reports 99031 deaths. In gen...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>States reported 1121 deaths a small rise from ...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>#IndiaFightsCorona: We have 1524 #COVID testin...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Populous states can generate large case counts...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                              tweet label\n",
       "0  1.0  The CDC currently reports 99031 deaths. In gen...  real\n",
       "1  2.0  States reported 1121 deaths a small rise from ...  real\n",
       "2  3.0  Politically Correct Woman (Almost) Uses Pandem...  fake\n",
       "3  4.0  #IndiaFightsCorona: We have 1524 #COVID testin...  real\n",
       "4  5.0  Populous states can generate large case counts...  real"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Prints top 5 rows of excel file\n",
    "\"\"\"\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Drops the rows containing Null values\n",
    "\"\"\"\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Drops the independent features, and stores it into X\n",
    "\"\"\"\n",
    "X=df.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['label']\n",
    "\"\"\"\n",
    "    Drops the dependent features, and stores it into y\n",
    "\"\"\"\n",
    "type(y)\n",
    "arr=[]\n",
    "for i in y:\n",
    "    if i=='real':\n",
    "        arr.append([1])\n",
    "    else:\n",
    "        arr.append([0])\n",
    "\"\"\"\n",
    "    Here, we are converting 'real' and 'fake' to '1' and '0' respectively.\n",
    "\"\"\"\n",
    "y=arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\"\"\"\n",
    "    It can be used across a range of tasks but has a particular focus\n",
    "    on training and inference of deep neural networks.\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\"\"\"\n",
    "    embedding is a dense vector of floating point values\n",
    "    (the length of the vector is a parameter that is specified).\n",
    "\"\"\"\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\"\"\"\n",
    "    To make each input length fixed\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "\"\"\"\n",
    "    A Sequential model is appropriate for a plain stack of layers \n",
    "    where each layer has exactly one input tensor and one output tensor.\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "\"\"\"\n",
    "    One-hot encodes a text into a list of word indexes of size n.\n",
    "    It returns a list of encoded integers each corresponding to a word \n",
    "    (or token) in the given input string.\n",
    "\n",
    "\"\"\"\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\"\"\"\n",
    "    Imports LSTM Classificatio model from Keras\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "    Dense implements the operation:\n",
    "    output = activation(dot(input, kernel) + bias). \n",
    "    These are all attributes of Dense. \n",
    "\"\"\"\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Specify the vocabulary size, to be used later.\n",
    "\"\"\"\n",
    "voc_size=5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Copies the tuple X into variable messages.\n",
    "\"\"\"\n",
    "messages=X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Reset the index, or a level of messages dataframe \n",
    "    to get a new order of arrangement.\n",
    "\"\"\"\n",
    "messages.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Pradhan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\"\"\"\n",
    "    It is a suite of libraries and programs for symbolic and statistical natural language \n",
    "    processing (NLP) for English written in the Python programming language. \n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "    A regular expression (or RE) specifies a set of strings that matches it. The functions \n",
    "    in this module is to check if a particular string matches a given regular expression.\n",
    "\"\"\"\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Preprocessing is done here.\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\"\"\"\n",
    "    Algorithm to for removing the commoner morphological \n",
    "    and inflexional endings from words in English. \n",
    "\"\"\"\n",
    "\n",
    "ps = PorterStemmer()\n",
    "corpus = []\n",
    "\n",
    "\"\"\"\n",
    "        In this loop, the words in the dataframe 'messages' is splitted and then joined \n",
    "        after adding the blank spaces between the words and stored in tuple variable 'review'.\n",
    "        Followed by this, all the stopwords are removed.\n",
    "\"\"\"\n",
    "for i in range(0, len(messages)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', messages['tweet'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    One-hot encodes a text into a list of word indexes of size n.\n",
    "    It returns a list of encoded integers each corresponding to a word \n",
    "    (or token) in the given input string.\n",
    "\"\"\"\n",
    "onehot_repr=[one_hot(words,voc_size)for words in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0 3921 ... 3859 2223 4555]\n",
      " [   0    0    0 ... 2867 3553 1293]\n",
      " [   0    0    0 ... 2696 2321  517]\n",
      " ...\n",
      " [   0    0    0 ... 4013 3714  329]\n",
      " [   0    0    0 ... 1722 4266 2287]\n",
      " [3067 4242    6 ...  471 2921 1003]]\n"
     ]
    }
   ],
   "source": [
    "sent_length=20\n",
    "\"\"\"\n",
    "    Maximum Sentence Length in the tweet.\n",
    "\"\"\"\n",
    "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
    "\"\"\"\n",
    "    Here we are padding before each sequence where the maximum length = sent_length\n",
    "\"\"\"\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 20, 40)            200000    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               56400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,501\n",
      "Trainable params: 256,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Creating the model\n",
    "embedding_vector_features=40\n",
    "model=Sequential()\n",
    "\"\"\"\n",
    "    Sequential model is a linear stack of layers.\n",
    "\"\"\"\n",
    "model.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\n",
    "\"\"\"\n",
    "    We're adding different features to the sequential model\n",
    "\"\"\"\n",
    "model.add(LSTM(100))\n",
    "\"\"\"\n",
    "    It is the number of LSTM memory units connected to each input of the series.\n",
    "\"\"\"\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\"\"\"\n",
    "    Here we're are using the layer activation funtion 'sigmoid'.\n",
    "\"\"\"\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\"\"\"\n",
    "    Binary cross entropy compares each of the predicted probabilities to \n",
    "    actual class output which can be either 0 or 1, and use it as a loss funtion.\n",
    "    \n",
    "    Adam optimizer involves a combination of two gradient descent methodologies: \n",
    "        - Momentum.\n",
    "        - Root Mean Square Propagation (RMSP). \n",
    "\"\"\"\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    We're converting the datatype from list to array.\n",
    "\"\"\"\n",
    "X_final=embedded_docs\n",
    "\n",
    "import numpy as np\n",
    "y_final=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\"\"\"\n",
    "    Here we are spliting the dataset, where the test_size is 1/3 of all data and we are initializing the\n",
    "    internal randoms number generator as 42.\n",
    "\"\"\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "68/68 [==============================] - 13s 92ms/step - loss: 0.4638 - accuracy: 0.7882 - val_loss: 0.2847 - val_accuracy: 0.8806\n",
      "Epoch 2/15\n",
      "68/68 [==============================] - 3s 49ms/step - loss: 0.1818 - accuracy: 0.9296 - val_loss: 0.2319 - val_accuracy: 0.9113\n",
      "Epoch 3/15\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.0896 - accuracy: 0.9707 - val_loss: 0.2692 - val_accuracy: 0.9018\n",
      "Epoch 4/15\n",
      "68/68 [==============================] - 4s 52ms/step - loss: 0.0440 - accuracy: 0.9886 - val_loss: 0.3512 - val_accuracy: 0.8938\n",
      "Epoch 5/15\n",
      "68/68 [==============================] - 3s 51ms/step - loss: 0.0362 - accuracy: 0.9919 - val_loss: 0.3098 - val_accuracy: 0.9000\n",
      "Epoch 6/15\n",
      "68/68 [==============================] - 3s 44ms/step - loss: 0.0207 - accuracy: 0.9965 - val_loss: 0.4128 - val_accuracy: 0.8924\n",
      "Epoch 7/15\n",
      "68/68 [==============================] - 3s 41ms/step - loss: 0.0127 - accuracy: 0.9972 - val_loss: 0.5164 - val_accuracy: 0.8886\n",
      "Epoch 8/15\n",
      "68/68 [==============================] - 3s 45ms/step - loss: 0.0140 - accuracy: 0.9972 - val_loss: 0.5016 - val_accuracy: 0.8853\n",
      "Epoch 9/15\n",
      "68/68 [==============================] - 4s 52ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 0.5463 - val_accuracy: 0.8886\n",
      "Epoch 10/15\n",
      "68/68 [==============================] - 3s 48ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.5076 - val_accuracy: 0.8910\n",
      "Epoch 11/15\n",
      "68/68 [==============================] - 3s 39ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.6515 - val_accuracy: 0.8863\n",
      "Epoch 12/15\n",
      "68/68 [==============================] - 3s 40ms/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 0.5598 - val_accuracy: 0.8882\n",
      "Epoch 13/15\n",
      "68/68 [==============================] - 2s 31ms/step - loss: 9.9783e-04 - accuracy: 1.0000 - val_loss: 0.6467 - val_accuracy: 0.8867\n",
      "Epoch 14/15\n",
      "68/68 [==============================] - 2s 30ms/step - loss: 5.4465e-04 - accuracy: 1.0000 - val_loss: 0.6862 - val_accuracy: 0.8858\n",
      "Epoch 15/15\n",
      "68/68 [==============================] - 3s 39ms/step - loss: 3.9554e-04 - accuracy: 1.0000 - val_loss: 0.6834 - val_accuracy: 0.8891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bcc1d31d90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "    Here we are training the model where epochs is the number of times we iterate over the training set \n",
    "    and the number of training examples utilized in one iteration.\n",
    "\"\"\"\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=15,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\"\"\"\n",
    "    Dropout is a technique used to prevent a model from overfitting.\n",
    "\"\"\"\n",
    "model.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    The model is fitted with trained data, and then used to make prediction.\n",
    "\"\"\"\n",
    "y_pred=(model.predict(X_test) >= 0.5).astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    to plot a sklearn confusion matrix(cm)\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    \"\"\"\n",
    "        Accuracy (all correct / all) = (TP + TN) / (TP + TN + FP + FN)\n",
    "    \"\"\"\n",
    "    \n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('YlOrRd') \n",
    "    \"\"\" \n",
    "        To select the colour theme of the confusion matrix\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    \"\"\"\n",
    "        To create a figure with the given width, height in inches.\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    \"\"\"\n",
    "       To display data as an image, i.e., on a 2D regular raster.\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    \"\"\"\n",
    "       To display a title and colorbar on the axes.\n",
    "    \"\"\"\n",
    "    \n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "        \n",
    "    \"\"\"\n",
    "        To put the labels on the confusion matrix, with or without rotation.\n",
    "    \"\"\"\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \"\"\"\n",
    "        To normalize the confusion matrix by slicing and adding a new axis.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    \"\"\"\n",
    "        To calculate the threshold by finding the maximum value in confusion matrix.\n",
    "    \"\"\"\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    \"\"\"\n",
    "        To display the values in the confusion matrix with different colours and precision.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \"\"\"\n",
    "        This automatically adjusts subplot params so that the subplot(s) fits in to the figure area. \n",
    "    \"\"\"\n",
    "    \n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \"\"\"\n",
    "        To plot the the labels on their respective axes.\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "        To show the confusion matix on screen.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def print_metrices(y_pred,y_test):\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred,))\n",
    "    print(\"Accuracy : \",accuracy_score(y_pred,y_test))\n",
    "    print(\"Precison : \",precision_score(y_pred,y_test, average = 'weighted'))\n",
    "    print(\"Recall : \",recall_score(y_pred,y_test,  average = 'weighted'))\n",
    "    print(\"F1 : \",f1_score(y_pred,y_test,  average = 'weighted'))\n",
    "    \"\"\"\n",
    "        Here, we are printing the confusion matrix, its accuracy, precision, recall and F1 score.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM\n",
      "val:\n",
      "[[ 873  131]\n",
      " [ 104 1011]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88      1004\n",
      "           1       0.89      0.91      0.90      1115\n",
      "\n",
      "    accuracy                           0.89      2119\n",
      "   macro avg       0.89      0.89      0.89      2119\n",
      "weighted avg       0.89      0.89      0.89      2119\n",
      "\n",
      "Accuracy :  0.8890986314299197\n",
      "Precison :  0.8895726865107643\n",
      "Recall :  0.8890986314299197\n",
      "F1 :  0.889191050952668\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('LSTM')\n",
    "print ('val:')\n",
    "print_metrices(y_pred,y_test)\n",
    "\"\"\"\n",
    "    Transform the data from the excel sheet which are not under 'label' \n",
    "    column and apply predict with the final estimator.\n",
    "\n",
    "    This will be used later to print additional informations, like data types and memory used.\n",
    "\"\"\"\n",
    "create_confusion_matrix(confusion_matrix(y_test,y_pred),target_names=['fake','real'], normalize = False, \\\n",
    "                      title = 'Confusion matix of LSTM on data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
