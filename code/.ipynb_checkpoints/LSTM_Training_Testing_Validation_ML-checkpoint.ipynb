{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\"\"\"\n",
    "    Used for data manipulation and analysis\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\"\"\"\n",
    "Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python. \n",
    "\"\"\"\n",
    "\n",
    "import itertools\n",
    "\"\"\" \n",
    "    Itertools is a module in python, it is used to iterate over data structures that can be stepped over using a \n",
    "    for-loop. Such data structures are also known as iterables.\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\"\"\"\n",
    "    classification_report builds a text report showing the main classification metrics. \n",
    "    confusion_matrix computes confusion matrix to evaluate the accuracy of a classification.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "    accuracy_score used to calculate the accuracy of either the faction or count of correct prediction in Python Scikit learn.\n",
    "    Compute the F1 score, also known as balanced F-score or F-measure.\n",
    "    \n",
    "    The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. \n",
    "    The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
    "    The best value is 1 and the worst value is 0.\n",
    "    \n",
    "    The recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. \n",
    "    The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "    The best value is 1 and the worst value is 0.\n",
    "    \n",
    "    The F1 score can be interpreted as a harmonic mean of the precision and recall, where an F1 score reaches \n",
    "    its best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal.\n",
    "    \n",
    "    This metric is calculated as:\n",
    "    F1 Score = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "\"\"\"\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Read an Excel file into a pandas DataFrame\n",
    "\"\"\"\n",
    "df=pd.read_excel('../data/Constraint_Train.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>The CDC currently reports 99031 deaths. In gen...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>States reported 1121 deaths a small rise from ...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>#IndiaFightsCorona: We have 1524 #COVID testin...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Populous states can generate large case counts...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                              tweet label\n",
       "0  1.0  The CDC currently reports 99031 deaths. In gen...  real\n",
       "1  2.0  States reported 1121 deaths a small rise from ...  real\n",
       "2  3.0  Politically Correct Woman (Almost) Uses Pandem...  fake\n",
       "3  4.0  #IndiaFightsCorona: We have 1524 #COVID testin...  real\n",
       "4  5.0  Populous states can generate large case counts...  real"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Prints top 5 rows of excel file\n",
    "\"\"\"\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Drops the rows containing Null values\n",
    "\"\"\"\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Drops the independent features, and stores it into X\n",
    "\"\"\"\n",
    "X=df.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['label']\n",
    "\"\"\"\n",
    "    Drops the dependent features, and stores it into y\n",
    "\"\"\"\n",
    "type(y)\n",
    "arr=[]\n",
    "for i in y:\n",
    "    if i=='real':\n",
    "        arr.append([1])\n",
    "    else:\n",
    "        arr.append([0])\n",
    "\"\"\"\n",
    "    Here, we are converting 'real' and 'fake' to '1' and '0' respectively.\n",
    "\"\"\"\n",
    "y=arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\"\"\"\n",
    "    It can be used across a range of tasks but has a particular focus\n",
    "    on training and inference of deep neural networks.\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\"\"\"\n",
    "    embedding is a dense vector of floating point values\n",
    "    (the length of the vector is a parameter that is specified).\n",
    "\"\"\"\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\"\"\"\n",
    "    To make each input length fixed\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "\"\"\"\n",
    "    A Sequential model is appropriate for a plain stack of layers \n",
    "    where each layer has exactly one input tensor and one output tensor.\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "\"\"\"\n",
    "    One-hot encodes a text into a list of word indexes of size n.\n",
    "    It returns a list of encoded integers each corresponding to a word \n",
    "    (or token) in the given input string.\n",
    "\n",
    "\"\"\"\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\"\"\"\n",
    "    Imports LSTM Classificatio model from Keras\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "    Dense implements the operation:\n",
    "    output = activation(dot(input, kernel) + bias). \n",
    "    These are all attributes of Dense. \n",
    "\"\"\"\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Specify the vocabulary size, to be used later.\n",
    "\"\"\"\n",
    "voc_size=5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Copies the tuple X into variable messages.\n",
    "\"\"\"\n",
    "messages=X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Reset the index, or a level of messages dataframe \n",
    "    to get a new order of arrangement.\n",
    "\"\"\"\n",
    "messages.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Pradhan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\"\"\"\n",
    "    It is a suite of libraries and programs for symbolic and statistical natural language \n",
    "    processing (NLP) for English written in the Python programming language. \n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "    A regular expression (or RE) specifies a set of strings that matches it. The functions \n",
    "    in this module is to check if a particular string matches a given regular expression.\n",
    "\"\"\"\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Preprocessing is done here.\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\"\"\"\n",
    "    Algorithm to for removing the commoner morphological \n",
    "    and inflexional endings from words in English. \n",
    "\"\"\"\n",
    "\n",
    "ps = PorterStemmer()\n",
    "corpus = []\n",
    "\n",
    "\"\"\"\n",
    "        In this loop, the words in the dataframe 'messages' is splitted and then joined \n",
    "        after adding the blank spaces between the words and stored in tuple variable 'review'.\n",
    "        Followed by this, all the stopwords are removed.\n",
    "\"\"\"\n",
    "for i in range(0, len(messages)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', messages['tweet'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    One-hot encodes a text into a list of word indexes of size n.\n",
    "    It returns a list of encoded integers each corresponding to a word \n",
    "    (or token) in the given input string.\n",
    "\"\"\"\n",
    "onehot_repr=[one_hot(words,voc_size)for words in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0  797 ... 1545  350 3161]\n",
      " [   0    0    0 ... 2542 3587 3586]\n",
      " [   0    0    0 ... 4179  748 3229]\n",
      " ...\n",
      " [   0    0    0 ... 2683  877  663]\n",
      " [   0    0    0 ...  419 4101  760]\n",
      " [1613 1633 2509 ... 2504 4797 4782]]\n"
     ]
    }
   ],
   "source": [
    "sent_length=20\n",
    "\"\"\"\n",
    "    Maximum Sentence Length in the tweet.\n",
    "\"\"\"\n",
    "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
    "\"\"\"\n",
    "    Here we are padding before each sequence where the maximum length = sent_length\n",
    "\"\"\"\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 20, 40)            200000    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               56400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,501\n",
      "Trainable params: 256,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Creating the model\n",
    "embedding_vector_features=40\n",
    "model=Sequential()\n",
    "\"\"\"\n",
    "    Sequential model is a linear stack of layers.\n",
    "\"\"\"\n",
    "model.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\n",
    "\"\"\"\n",
    "    We're adding different features to the sequential model\n",
    "\"\"\"\n",
    "model.add(LSTM(100))\n",
    "\"\"\"\n",
    "    It is the number of LSTM memory units connected to each input of the series.\n",
    "\"\"\"\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\"\"\"\n",
    "    Here we're are using the layer activation funtion 'sigmoid'.\n",
    "\"\"\"\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\"\"\"\n",
    "    Binary cross entropy compares each of the predicted probabilities to \n",
    "    actual class output which can be either 0 or 1, and use it as a loss funtion.\n",
    "    \n",
    "    Adam optimizer involves a combination of two gradient descent methodologies: \n",
    "        - Momentum.\n",
    "        - Root Mean Square Propagation (RMSP). \n",
    "\"\"\"\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    We're converting the datatype from list to array.\n",
    "\"\"\"\n",
    "X_final=embedded_docs\n",
    "\n",
    "import numpy as np\n",
    "y_final=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\"\"\"\n",
    "    Here we are spliting the dataset, where the test_size is 1/3 of all data and we are initializing the\n",
    "    internal randoms number generator as 42.\n",
    "\"\"\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "68/68 [==============================] - 9s 71ms/step - loss: 0.4589 - accuracy: 0.7740 - val_loss: 0.2841 - val_accuracy: 0.8853\n",
      "Epoch 2/15\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 0.1705 - accuracy: 0.9393 - val_loss: 0.2816 - val_accuracy: 0.8985\n",
      "Epoch 3/15\n",
      "68/68 [==============================] - 4s 54ms/step - loss: 0.0797 - accuracy: 0.9749 - val_loss: 0.3944 - val_accuracy: 0.8867\n",
      "Epoch 4/15\n",
      "68/68 [==============================] - 3s 51ms/step - loss: 0.0376 - accuracy: 0.9893 - val_loss: 0.3841 - val_accuracy: 0.8820\n",
      "Epoch 5/15\n",
      "68/68 [==============================] - 3s 48ms/step - loss: 0.0263 - accuracy: 0.9933 - val_loss: 0.4688 - val_accuracy: 0.8697\n",
      "Epoch 6/15\n",
      "68/68 [==============================] - 4s 52ms/step - loss: 0.0227 - accuracy: 0.9944 - val_loss: 0.4556 - val_accuracy: 0.8886\n",
      "Epoch 7/15\n",
      "68/68 [==============================] - 3s 50ms/step - loss: 0.0072 - accuracy: 0.9986 - val_loss: 0.6609 - val_accuracy: 0.8849\n",
      "Epoch 8/15\n",
      "68/68 [==============================] - 3s 47ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.6378 - val_accuracy: 0.8806\n",
      "Epoch 9/15\n",
      "68/68 [==============================] - 3s 46ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.7504 - val_accuracy: 0.8882\n",
      "Epoch 10/15\n",
      "68/68 [==============================] - 4s 60ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.7407 - val_accuracy: 0.8844\n",
      "Epoch 11/15\n",
      "68/68 [==============================] - 3s 47ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.4707 - val_accuracy: 0.8910\n",
      "Epoch 12/15\n",
      "68/68 [==============================] - 3s 43ms/step - loss: 0.0050 - accuracy: 0.9993 - val_loss: 0.6020 - val_accuracy: 0.8863\n",
      "Epoch 13/15\n",
      "68/68 [==============================] - 3s 41ms/step - loss: 7.1079e-04 - accuracy: 1.0000 - val_loss: 0.6852 - val_accuracy: 0.8849\n",
      "Epoch 14/15\n",
      "68/68 [==============================] - 3s 41ms/step - loss: 3.8349e-04 - accuracy: 1.0000 - val_loss: 0.7229 - val_accuracy: 0.8806\n",
      "Epoch 15/15\n",
      "68/68 [==============================] - 3s 44ms/step - loss: 2.9402e-04 - accuracy: 1.0000 - val_loss: 0.7829 - val_accuracy: 0.8834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24eab93b4c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "    Here we are training the model where epochs is the number of times we iterate over the training set \n",
    "    and the number of training examples utilized in one iteration.\n",
    "\"\"\"\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=15,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\"\"\"\n",
    "    Dropout is a technique used to prevent a model from overfitting.\n",
    "\"\"\"\n",
    "model.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    The model is fitted with trained data, and then used to make prediction.\n",
    "\"\"\"\n",
    "y_pred=(model.predict(X_test) >= 0.5).astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    to plot a sklearn confusion matrix(cm)\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    \"\"\"\n",
    "        Accuracy (all correct / all) = (TP + TN) / (TP + TN + FP + FN)\n",
    "    \"\"\"\n",
    "    \n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('YlOrRd') \n",
    "    \"\"\" \n",
    "        To select the colour theme of the confusion matrix\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    \"\"\"\n",
    "        To create a figure with the given width, height in inches.\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    \"\"\"\n",
    "       To display data as an image, i.e., on a 2D regular raster.\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    \"\"\"\n",
    "       To display a title and colorbar on the axes.\n",
    "    \"\"\"\n",
    "    \n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "        \n",
    "    \"\"\"\n",
    "        To put the labels on the confusion matrix, with or without rotation.\n",
    "    \"\"\"\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \"\"\"\n",
    "        To normalize the confusion matrix by slicing and adding a new axis.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    \"\"\"\n",
    "        To calculate the threshold by finding the maximum value in confusion matrix.\n",
    "    \"\"\"\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    \"\"\"\n",
    "        To display the values in the confusion matrix with different colours and precision.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \"\"\"\n",
    "        This automatically adjusts subplot params so that the subplot(s) fits in to the figure area. \n",
    "    \"\"\"\n",
    "    \n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \"\"\"\n",
    "        To plot the the labels on their respective axes.\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "        To show the confusion matix on screen.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def print_metrices(y_pred,y_test):\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred,))\n",
    "    print(\"Accuracy : \",accuracy_score(y_pred,y_test))\n",
    "    print(\"Precison : \",precision_score(y_pred,y_test, average = 'weighted'))\n",
    "    print(\"Recall : \",recall_score(y_pred,y_test,  average = 'weighted'))\n",
    "    print(\"F1 : \",f1_score(y_pred,y_test,  average = 'weighted'))\n",
    "    \"\"\"\n",
    "        Here, we are printing the confusion matrix, its accuracy, precision, recall and F1 score.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM\n",
      "val:\n",
      "[[ 866  138]\n",
      " [ 109 1006]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.88      1004\n",
      "           1       0.88      0.90      0.89      1115\n",
      "\n",
      "    accuracy                           0.88      2119\n",
      "   macro avg       0.88      0.88      0.88      2119\n",
      "weighted avg       0.88      0.88      0.88      2119\n",
      "\n",
      "Accuracy :  0.8834355828220859\n",
      "Precison :  0.8839788004711737\n",
      "Recall :  0.8834355828220859\n",
      "F1 :  0.8835414423626988\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAEmCAYAAADbUaM7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAryUlEQVR4nO3deZhU1Z3G8e/boOKGgAgiiLigBlHQIFFjXOKGxoiaqKiJuCSOW4zRLJqZxEiGhMxkX5zEJSNJXII7biDREKNxAyQqoEJEBUGQVVkF+c0f9zQWPd1N9e3qrqb6/TzPferWudu5VV2/Pvfcc89RRGBmZvlUlTsDZmabMgdRM7NGcBA1M2sEB1Ezs0ZwEDUzawQHUTOzRnAQLZKkLSU9IGmppDsbsZ+zJT1ayrw1B0mfkvRqE+y3JJ9rayLpe5L+1ID1Q9IeTZmn1qzigqiksyRNkLRM0lxJj0g6tAS7/jzQFdg+Ik7Lu5OIuDUiji1BfppUzR9eRPw9IvZqgkPV+7nWFzAkHSrpHykAL5L0lKQDJX07ff/LJK2S9GHB+ykF5zdPUtuC/bWVNF9Sq2w8LalX+lzabnxtq1ZRQVTSlcDPgR+Q/TB7AtcDg0uw+12A1yJibQn2ZR/J9blKag88CPwK6AR0B64DVkfEDyJim4jYBrgIeLr6fUTsU7CbJcDxBe9PABbnPxVrlSKiIiZgO2AZcFo962xBFmTnpOnnwBZp2RHAbOAqYD4wFzgvLbsO+ABYk45xAfA94E8F++4FBNA2vT8XeB14H5gJnF2Q/mTBdocAzwNL0+shBcvGA98Hnkr7eRToXMe5Vef/mwX5P5ksMLwGLAK+XbD+QOBpskAyF/g1sHla9kQ6l+XpfM+o3n9avnva3wHp/U7AAuCIOvL2sXQuS4ApwEl1fa61bLvB51yQPgBYUsTfxQafd0F6AP8B3FmQdhfw70DUs79azyUtuwX4DfBQ+r6eBXavYz9jgMtqpP0TODXN/wKYBbwHTAQ+tbHPpGD5N9J3Ogc4P53rHmnZZ4AX0n5nAd8r2O6ttO6yNB2cvuvHgYXpO74V6FDu33tLmsqegZKdCAwC1pKCWB3rDAOeAboAOwD/AL6flh2Rth8GbEYWfFYAHdPyDf5wa3nfK/0BtgW2Tn+ke6Vl3YB90vz6HzVZCWox8MW03Znp/fZp+XjgX8CewJbp/Yg6zq06/99N+f8y8C5wG7AtsA+wCtgtrf9x4KB03F7ANOCKgv2t/+EV7H92wfsvp222AsYCP64jX5sBM4BvA5sDnyYLMHvV9jnWsn2ty4H26Yc9kqw02bGO7dd/3jXSA+gLzAM6pGleSouc53IL2T+XgelzvRW4o459nQM8VfC+D1lgrv6n/gVg+7Sfq4B3gHYb+8zIfgfV57F1+v4Lg+gRwL5kV6H7pXVPrvk3XLC/PYBjyAogO5D9g/15uX/vLWmqpMv57YEFUf9l4dnAsIiYHxHvkpWEvliwfE1aviYiHib7b5y3HnAd0FfSlhExNyKm1LLOZ4DpEfHHiFgbEbcDrwCfLVjnfyPitYhYCYwC+tdzzDXA8IhYA9wBdAZ+ERHvp+NPIfvhEBETI+KZdNw3gN8Bhxd7chFxIzCdrLTVjawEV5uDgG3Igv8HEfE42WX4mcUeq47jvwccSvajvxF4V9JoSV0bsJtVwANkJe0hwOiUVpdizuWeiHgu/R3eSt3f171Af0m7pPdnp21Xp/P7U0QsTN/PT8iCWDF/i6eT/c28HBHLyQLuehExPiJeioh1EfEicDv1fO8RMSMixkXE6vSb+Wl967dGlRREFwKdN1IpvhPwZsH7N1Pa+n3UCMIryH40DZL+eM8gq4+bK+khSXsXkZ/qPHUveP9OA/KzMCI+TPMr0+u8guUrq7eXtKekByW9I+k9snrkzvXsuzY3kpV4flX946/FTsCsiFhXkFbzHHOJiGkRcW5E9Ej52ImsiqYh/kBWKjwnzdenmHMp6vuKiPfJLvuHpKQhZEEXAElXSZqWbpotIauuKub72YnsMr0wf+tJ+oSkv0p6V9JSsr/ROvcrqYukOyS9nf5O/lRkPlqNSgqiT5OVIk6uZ505ZDcyqvVMaXksJ7uUrbZj4cKIGBsRx5CV0l4hCzgby091nt7OmaeG+B+yfPWOiPZkl6gqdmNJ25AFrJuB70nqVMeqc4CdJRX+rZX8HCPiFbLL6b4N3PTvZN9RV+DJjaxb6nO5HThT0sFk1TV/haw5GfAtslJlx4joQFZnXsz3MxfYuUb+Ct1GVuLeOSK2A35bsN/aWiX8MKXvl/5OvlBkPlqNigmiEbGUrD7wN5JOlrSVpM0kHS/pv9JqtwP/IWkHSZ3T+kW3t6thMnCYpJ6StgOuqV4gqaukkyRtDawmqxb4sJZ9PAzsmZpltZV0Blnd2IM589QQ25LV2y5LpeSLayyfB+xWz/a/ACZGxJfISlS/rWO9Z8n+4XwzfR9HkFVX3NGAvFZJalcwbSFp71Ra6wEgaWeyy+pnGrDfrPIzy89Jab4+pTiXQg+T/RMdBvy5oIS7LVn99rtAW0nfJasDLsYo4FxJfSRtBVxbY/m2wKKIWCVpIHBWwbJ3yaqhdqux/jJgiaTuZDetrEDFBFGAiPgpcCXZXdd3yS5rLgPuS6v8JzABeBF4CZiU0vIcaxzw57SviWwY+KrIbgbMIbvRcDhwSS37WAicmNZdSHZn/cSIWJAnTw30dbIf0PtkpeQ/11j+PWCkpCWSTi9cIGkw2Q2Mi1LSlcABks6ueZCI+AA4iezmzwKyJmfnpJJjsc4kq4qonv6V8v0J4FlJy8mC58tkn2WDRMSUOuqsa65XinMp3N9q4B7gaLISYrWxwCNkrSreJLvCmvX/dlD7Ph8hu0J4nOwm2OM1VrkEGCbpfbJCxKiCbVcAw4Gn0vd+ENl9gwPISsIPpfxaAW38n6+ZmdWlokqiZmbNzUHUzKwRHETNzBrBQdTMNnmSfp86j3m5IK2TpHGSpqfXjgXLrpE0Q9Krko4rSP+4pJfSsl9K2mhzroq4sdRBbWJHbVbubFgO2+xfs5msbSomTnptQUTskGfbPbR1rKi11V/t5rJ6bEQMqmu5pMPImmL9ISL6prT/ImvONULS1WRtbr8lqQ9Zc8eBZA8n/AXYMyI+lPQc8FWy1h4PA79MLR7qVBFdXu2ozfh92x7lzoblcMgzN5Q7C5aTNj+i5tN2RVvJh1z8/54zqdt3ea3ep6Qi4glJvWokDybrKwCyPhbGkz3EMJisT4PVwExJM4CBkt4A2kfE0wCS/kD28E7lB1Ez2/Q0sC6xs6QJBe9viIiN/QfuGhFzASJirqQuKb07Gz6UMTulrUnzNdPr5SBqZs1ONDiILoiIASU8fE1RT3q9fGPJzMqiqgFTTvMkdQNIr/NT+mw27F+gB9nThbPTfM30jZ6HmVmza4YgOhoYmuaHAvcXpA9JfTDsCvQGnkuX/u9LOijdlT+nYJs6+XLezJqdgDal3J90O9lNpM6SZpN1vDICGCXpArJe+0+DrK8ESaOAqWQdvVxa0IXkxWS9gW1JdkOp3ptK4CBqZmVSysvgiKirk++j6lh/OFlnKzXTJ9DA7hQdRM2s2eW4sdRiOYiaWVk4iJqZ5eSSqJlZIzmImpk1goOomVlOonKCT6Wch5ltQlwnambWSA6iZmaNUCmD1zuImlmz8+W8mVkjOYiameXku/NmZo3kkqiZWU6uEzUza6RKCaKVch5mtgmpLomWqmd7SV+V9LKkKZKuSGkNHnc+DwdRMyuLUgVRSX2BL5ONI98POFFSb+Bq4LGI6A08lt6Txp0fAuwDDAKul5S7o30HUTNrdtXDgxQ7bcTHgGciYkVErAX+BpxCNr78yLTOSLIx5KFg3PmImAnMIAvAuTiImllZlPBy/mXgMEnbS9oKOIFsNM8Nxp0HCsedn1WwfVHjy9fFN5bMrCwaWILrLGlCwfsbIuIGgIiYJulHwDhgGfBPsgHo6pJrfPm6OIiaWbPL0cRpQUQMqGthRNwM3Awg6Qdkpct5krpFxNwix53PxZfzZlYWUvHTxvelLum1J3AqcDsNHHc+73m4JGpmZVGlBlxBb3zVuyVtD6whG0d+saQ84843mIOomTU7UVwJs1gR8ala0hbSwHHn83AQNbOyaFBJtAVzEDWz5ldkXeemwEHUzMrCQdTMLCfhy3kzs0apkIKog6iZlYcv583McpKCqipfzpuZ5VblkqiZWX6+nDczawTl7zipRXEQNbNmV+rHPsvJQdTMysJB1MwsL0Eb3503M8tHuLG9mVmjyI99mpnlVyl1oh4exMzKokrFTxsj6WuSpkh6WdLtktpJ6iRpnKTp6bVjwfrXSJoh6VVJxzXqPBqzsZVGt8vPo//kR+j/wsP0/uPP0BabA7DjJV9k/5cfpf/kR9jlh99cv/5W++7Fvk/cSf/Jj9Bv0kPr17fmdf6Xf0SX7ifTt/+569O+c+3N7HfA+fQfcAHHnvB15sxZAMCaNWsZev4P2Xf/8/jYvufwwx/dWqZctwzZ2ElR9FT/vtQduBwYEBF9yYaqHwJcDTwWEb2Bx9J7JPVJy/cBBgHXSypiePvaOYiW2eY7daXbpefw4kEnM3n/E1CbNnQ+/UTaH34QnT57NJMPOJHJ/Y9nzk9vyjZo04bet/yEf132HSb3P54pR59NrKlvdFhrKueeM4gxD/7XBmnfuGoIL076PZMn3MyJJxzMsOEjAbjzrvGsXv0BL73wv0x89gZ+d9No3nhjbjmy3WKoAVMR2gJbSmoLbEU2eudgYGRaPhI4Oc0PBu6IiNURMROYAQzMex4Ooi2A2ralast20KYNVVu244O589nx387i7f/+HfHBBwCseXcRAB2OOZQVL73KihdfAWDtoiWwbl25st6qHfapfnTquO0Gae3bb71+fvnyVShV/Eli+fJVrF27lpUrV7P5ZpttsG7rk3VAUuxEGne+YLpw/Z4i3gZ+TDYY3VxgaUQ8CnSNiLlpnblAl7RJd2BWQWZmp7RcHETL7IM585jzs5v4+L+e4MC3nubD995n6V+eZMvevWh/6IHs++Rd7POX29jm4/sCsGXvXYkIPvbg/7Lfs/ez01VfLvMZWE3//p2b2Hm307j19nEMu/Z8AD7/ucPZeut2dOv5OXrufgZfv/IMOnVqX+aclk/WKXOD6kQXRMSAgumG9fvK6joHA7sCOwFbS/rCRg5fU+6mAk0WRCVdLmmapForfySdK+nXTXX8TUWbDu3p9NmjmbjnkUzY5RCqtt6KzmcNRm3b0rZDe1469PO8efUI9rztlwCobRvaH/Jxpg+9kpePOIPtBx/LdkceXOazsELDv/8lZr1+J2efeQy/vv5eAJ57fhpt2rRhzpt3M/O12/nJz0bx+utzypzT8irhuPNHAzMj4t2IWAPcAxwCzJPULTuWugHz0/qzgZ0Ltu9BdvmfS1OWRC8BToiIs5vwGJu8Dkd9klVvzGbtgkXE2rUsum8s7Q86gNWz32HhfY8CsGzCi7AuaNu5E6vffof3/v4caxcuZt3KVSweM56t99+nzGdhtTlryFHcfe/fALjtjscYdOxANtusLV26dOSTh/RlwsRXy5zDMmpAAC0iiL4FHCRpK2X1J0cB04DRwNC0zlDg/jQ/GhgiaQtJuwK9gefynkqTBFFJvwV2A0ZL+pakf0h6Ib3uVcv6n5H0tKTOko5N85Mk3Slpm6bIY0ux+q05bPuJ/lmdKLDdkYew4pUZLBo9ju2OPAiAdr17oc03Y+2CRSx59O9ste/e6+tQ239qICunzSjnKViB6dNnr58f/eA/2HuvngD03LkLj4+fRESwfPlKnnl26vplrZWIoqf6RMSzwF3AJOAlsrh2AzACOEbSdOCY9J6ImAKMAqYCY4BLI+LDvOfRJI3tI+IiSYOAI4EPgJ9ExFpJRwM/AD5Xva6kU4ArgRPImib8B3B0RCyX9K20bFjNY6SK5QsBum7Czwwse/6fLLxnDPs9dz+s/ZBlk6cy76Y/QwR73DiC/i88zLoP1jD9gm8A8OGS95jzi9+z39P3QgSLx4xn8SPjy3sSrdSZXxjG+Ccms2DBUnrs+nmu++55PPzIs7z62ltUVVWxS8+u/PY3VwJw6cUnc96XfkTf/ucREZw39Hj222/3Mp9BeZWysX1EXAtcWyN5NVmptLb1hwPDS3FsRTTNo1eS3gAGAFsCvyQrMgewWUTsLelc4BvA+8CxEfGepBOBW8jqLAA2B56OiAvqO9beVe3i9217NMVpWBM7ZPnN5c6C5aTNj5gYEQPybNtvi83jkR13LHr97m/Nyn2sptYcRbjvA3+NiFMk9QLGFyx7neyyf09gAtlds3ERcWYz5MvMysiPfRZvO+DtNH9ujWVvAqcCf5C0D/AM8ElJewCkiuI9myGPZtasGtC+qYUPxtQcQfS/gB9KeoqsznMDEfEqcDZwJ9CeLNDeLulFsqC6dzPk0cyak0BVxU8tWZNdzkdErzS7gOxyvdp30vJbyOo/iYgXgD5p+b+AA5sqX2bWMqhCruc33dvaZrbJEi2/hFksB1EzKw+XRM3MchJUtXUQNTPLrUIKog6iZlYGcp2omVnjtPD2n8VyEDWzZid8OW9mlp+EXBI1M8uvqo2DqJlZPqJiBidyEDWzZldJdaIV8r/AzDY1qlLRU737kfaSNLlgek/SFZI6SRonaXp67ViwzTWSZkh6VdJxjTkPB1Eza34l7MUpIl6NiP4R0R/4OLACuBe4GngsInoDj6X3SOoDDAH2AQYB10v6fz3MFctB1MzKo4Qj1RU4CvhXRLxJNozyyJQ+Ejg5zQ8G7oiI1RExE5gBDMx7Gq4TNbPm1/Bn5ztLmlDw/obCsecLDAFuT/NdI2IuQETMldQlpXcn66u42uyUlouDqJk1uxw3lhZsbIwlSZsDJwHXFHH4mnIPNucgamZl0CSN7Y8HJkXEvPR+nqRuqRTaDZif0mcDOxds1wOYk/egrhM1s+anBk7FOZOPLuUBRgND0/xQ4P6C9CGStpC0K9lIxM/lPBOXRM2sPErZi5OkrYBjgH8rSB4BjJJ0AfAWcBpAREyRNAqYCqwFLo2ID/Me20HUzMqilJfzEbEC2L5G2kKyu/W1rT8cGF6KYzuImlnza3DLpZbLQdTMmp0AeXgQM7OchDtlNjNrlAppG+QgambNzyVRM7NGcknUzCwnqfJLopJ+RT3Pk0bE5U2SIzNrHVrB3fkJ9SwzM8uvNdSJRsTIwveSto6I5U2fJTNrFSqkTnSjpyHpYElTgWnpfT9J1zd5zsysclWXRIudWrBi/hf8HDgOWAgQEf8EDmvCPJlZa1D6XpzKoqi78xExSxs+6Jq7xxMzM6DFlzCLVUwQnSXpECBSz9GXky7tzcxykVrF3flqFwG/IBuD5G1gLHBpU2bKzFqBCimJbrRONCIWRMTZEdE1InaIiC+kfvrMzPIp4ZDJAJI6SLpL0iuSpqUb4i1j3HlJu0l6QNK7kuZLul/Sbo05qJlZie/O/wIYExF7A/3IqhxbzLjztwGjgG7ATsCdbDiOiZlZw4gs+hQ71bcrqT1Zi6GbASLig4hYQjONO19MEFVE/DEi1qbpTzRieFEzM6CUJdHdgHeB/5X0gqSbJG1NjXHngcJx52cVbN+ocefrDKKpPqET8FdJV0vqJWkXSd8EHsp7QDMzoKFBtLOkCQXThQV7agscAPxPROwPLCdduteh2cadn5h2XH3AwlH0Avh+3oOaWSvX8CZOCyJiQB3LZgOzI+LZ9P4usiDaLOPO1/fs/K55d2pmVq/qOtESiIh3JM2StFdEvEo2wufUNA0lGzq55rjzt0n6Kdl9nqYfd15SX6AP0K4g43/Ie1AzsxK3E/0KcGt6IOh14DyyMF3+ceclXQscQRZEHwaOB54EHETNLL8S9uIUEZOB2i73m3zc+WJO4/MpI+9ExHlkbbC2KMXBzayVqqBenIq5nF8ZEeskrU3tseaTNSkwM8uvQvoTLSaITpDUAbiR7I79MhpRCWtmhoC2lRFFNxpEI+KSNPtbSWOA9hHxYtNmy8wqXmXE0HoHqjugvmURMalpsmRmFa81jPYJ/KSeZQF8usR5yW2bA3bjkAl/LHc2LIfrdFa5s2DlUukl0Yg4sjkzYmatjCq/JGpm1jQ2gbGTiuUgambl4ZKomVkjVMiNpWJ6tpekL0j6bnrfU1LuDkzNzErZKXO5FZO964GDgTPT+/eB3zRZjsysdZCKn1qwYi7nPxERB0h6ASAiFqeeUszM8mvZsbFoxQTRNWkQpwCQtAOwrklzZWYVruWXMItVzOX8L4F7gS6ShpN1g/eDJs2VmVU+NWBqwYp5dv5WSRPJusMTcHJETGvynJlZ5RLQpoVHxyIVc3e+J7ACeICsW/3lKc3MLL8S3liS9IaklyRNljQhpXWSNE7S9PTasWD9ayTNkPSqpOMacxrF1Ik+xEcD1rUDdgVeJRv43swsn9IXRI+MiAUF768GHouIEZKuTu+/JakPMIQshu0E/EXSnnmHCNloSTQi9o2I/dJrb7JB7p/MczAzMyDVdTZ5E6fBwMg0PxI4uSD9johYHREzgRlkcS2XBjdjTV3gHZj3gGZm0OAYWt+485BdLT8qaWLBsq4RMRcgvXZJ6d2BWQXbzk5puRQzUN2VBW+rgAOAd/Me0MwMaGgJs75x5wE+GRFzJHUBxkl6pb4j15IWDclMoWLqRLctmF9LVkd6d94DmpkhlfTufETMSa/zJd1Ldnk+T1K3iJgrqRvZ+HCQlTx3Lti8BzAn77HrDaKpkf02EfGNvAcwM6tViWKopK2Bqoh4P80fCwwja000FBiRXu9Pm4wGbpP0U7IbS71pxLhx9Q0P0jYi1tY3TIiZWW6le2KpK3Cvsv21BW6LiDGSngdGSboAeAs4DSAipkgaBUwlu7q+NO+d+eoD1uU5svrPyZJGA3cCy6sXRsQ9eQ9qZlaqkmhEvA70qyV9IdlDQrVtMxwYXorjF1Mn2glYSDamUnV70QAcRM0sn+omThWgviDaJd2Zf5mPgme13HeyzMyAFv9MfLHqC6JtgG0ocXMAMzOgYnq2ry+Izo2IYc2WEzNrPUSrCKKVcYZm1jJVSISpL4jWelfLzKzxKqdT5jqDaEQsas6MmFkrUxkx1EMmm1kZtJI6UTOzplPpl/NmZk2qqoUPKF8kB1EzKwOBHETNzPJxnaiZWSO5TtTMLC9fzpuZNY5LomZmOUnQpk25c1ESlVGeNrNNT4mHTJbURtILkh5M7ztJGidpenrtWLDuNZJmSHpV0nGNOQ0HUTMrj9KPO/9VYFrB+6uBxyKiN/BYeo+kPsAQYB9gEHB9Gk8uFwdRM2t+IruxVOy0sd1JPYDPADcVJA8GRqb5kcDJBel3RMTqiJgJzCAbHTQXB1EzKwNl7USLnaCzpAkF04U1dvhz4JvAuoK0rhExFyC9dknp3YFZBevNTmm5+MaSmZVHw+7OL4iIAbXvRicC8yNioqQjijlyLWm5R+twEDWz8ihdO9FPAidJOgFoB7SX9CdgnqRuETFXUjdgflp/NrBzwfY9gDl5D+7LeTNrfhK0qSp+qkdEXBMRPSKiF9kNo8cj4gvAaGBoWm0ocH+aHw0MkbSFpF2B3mRDxOfikqiZlUfTP7E0Ahgl6QLgLeA0gIiYImkUMBVYC1waER/mPYiDqJmVRxM8sRQR44HxaX4hdQxzFBHDgeGlOKaDqJk1P+HHPs3M8msFA9WZmTWpCunZvjLOYhN2/vnX0aXLMfTte/r6tEWLlnLMMZfQu/cpHHPMJSxe/B4AH3ywhvPOu4599z2Dfv3OZPz4CeXKdqtz0s0/4Ovz/sHFLz1Q6/I2m2/G5+74GV+Z/igXPDOK7Xb5qO12v3NO5rLXxnLZa2Ppd87JG2z36f+8gsteHcMlUx9m4Fe+2JSn0LKILIgWO7VgLTt3rcC5536WMWN+tUHaiBG3cNRRA5k+/V6OOmogI0bcAsCNN94LwEsv/Zlx437DVVf9nHXr1tXcpTWBybfcw58GfanO5ftfcBqrFr/Hr3ofyzM/u4Wjf/R1ANp13I7Dr72Mmz5xOjcNPI3Dr72Mdh3aA9D/3FNpv3M3fr338Vzf5wRevuOhZjmXlkElfeyznFp27lqBww47gE6d2m+Qdv/9f2Po0BMBGDr0RO67bzwAU6fO5KijDgSgS5dOdOiwLRMmTG3W/LZWb/19AisXLa1z+V6DP80/R2b/5KbeNZbdjjoYgD2OO5TXxz3FqsVLWbXkPV4f9xR7DPoUAAMuPpO/DfsNRPawzIp3FzXxWbQwDXvss8VyEG2B5s1bRLdunQHo1q0z8+cvBqBfv97cf//fWLt2LTNnvs3EidOYNWteObNqSfvuXVk6ay4A8eGHrFr6Pltu35Ftu3dl6ax31q/33ux5bNu9KwAdd9+ZvmecwJefv5uzHr6RTnvsUpa8l03pe3EqixYfRCW9IalzufPREpx//kn06NGFAQPO4YorfsIhh+xH27aV0bHtJq+2H3oEqiMdoO0Wm7N21WpuPPBzTLpxFCf9/gdNnMkWRL6cz0WZlv2JtABdu3Zi7twFAMydu4AuXbK+ZNu2bcvPfnYVkyffxv33/5QlS5bRu3fPcmbVkvdmv8N2O3cDQG3a0G67bVm5aElK33H9eu17dOX9OfPTNvOYevejALxy7zi67rdX82e8nFwSLY6kXpKmSboemAR8R9Lzkl6UdF3BevdJmihpSi3dXLUqJ510OCNHPgjAyJEPMnjw4QCsWLGK5ctXAjBu3DO0bduGPn12K1s+W7sDLz2bAy89G4DXRj9Ov6GnANDn88cx8/FnAJgx9kl2O/ZQ2nVoT7sO7dnt2EOZMfZJAF657y/s+umDANjl8IEsfO2N5j+JcqqQINpc7UT3As4D7gM+T9YBqoDRkg6LiCeA8yNikaQtgecl3Z0e26pVCrQXAvTsuWNdq7V4Z575bcaPn8iCBUvo0eMErrvuQq6+eiinn34NN998Pz177sidd44AYP78RRx33GVUVVXRvXsX/vjHYWXOfetx6m0/odcRA9mqc0e+NutvjL/2V3TeezdmPTUJgEk338Upf/xvvjL9UVYuWspdQ74GwKrFS3ni+9fz5efvAuCJYb9h1eLsBtWTI27g1Ft/zEFfG8oHy1bwwJf+vTwnVxaCqsqoilJE7m70ijuA1Av4a0TsKunHZEF0SVq8DfDDiLhZ0veAU1J6L+C4iHhG0hvAgIhYUNcxBgzoExMm/LFpTsCa1HU6q9xZyO3MB37Ln0/9CuvWrCl3Vsrie7w2sa4+PjdmwL7d4vl7zi16/ao9R+Q+VlNrrpLo8vQqsqD5u8KFqSPVo4GDI2KFpPFk/QKatVi3f/aicmdh01Yht0ea+yzGAudL2gZAUndJXYDtgMUpgO4NHNTM+TKzZqcGTC1Xsz47HxGPSvoY8HRq+rEM+AIwBrhI0ovAq8AzzZkvM2tuLf+GUbGaPIhGxBtA34L3vwB+Ucuqx9exfa8myZiZlVeJLucltQOeALYgi2l3RcS1kjoBfya7x/IGcHpELE7bXANcAHwIXB4RY/MevzIqJcxs01O6xvargU9HRD+gPzBI0kF43Hkzq1wiCz/FTnWLzLL0drM0BR533swqVnXP9iVqbC+pjaTJZCN6jouIZ/G482ZW0Rp2Y6mzpMIOdG+IiBuq36SB5vpL6gDcK6lvzR0UHrmWNI87b2abmgYF0QXFNLaPiCWpnfkgPO68mVWu0vXiJGmHVAIlPTZ+NPAKHnfezCpa6Z5Y6gaMTHfYq4BREfGgpKfxuPNmVplUsiAaES8C+9eS7nHnzaxCido7rN4EOYiaWZk4iJqZ5VchvTg5iJpZGbT83pmK5SBqZuXhOlEzs0bI3+dHi+IgamZl4P5EzczyE76xZGbWOC6Jmpnl58t5M7O8qjtl3vQ5iJpZeVQ5iJqZ5eSSqJlZ47hO1MysMRxEzczyUen6Ey23yjgLM9v0lGi0T0k7S/qrpGmSpkj6akrvJGmcpOnptWPBNtdImiHpVUnHNeY0HETNrDzUpvipfmuBqyLiY8BBwKWS+gBXA49FRG/gsfSetGwIsA/ZgHbXp6FFcnEQNbMyUAOnukXE3IiYlObfB6aRjSM/GBiZVhsJnJzmBwN3RMTqiJgJzAAG5j0TB1EzK4+GXc53ljShYLqw9l2qF9l4S88CXSNiLmSBFuiSVusOzCrYbHZKy8U3lsysTBpUhtvouPOStgHuBq6IiPfqGcOptgXRkMwUcknUzJqfKNmNJQBJm5EF0Fsj4p6UPE9St7S8GzA/pc8Gdi7YvAcwJ++pOIiaWRmkJk7FTvXtKSty3gxMi4ifFiwaDQxN80OB+wvSh0jaQtKuQG/gubxn4st5MyuTkjW2/yTwReAlSZNT2reBEcAoSRcAbwGnAUTEFEmjgKlkd/YvjYgP8x7cQdTMykAlGx4kIp6k7oh8VB3bDAeGl+L4DqJmVh5+dt7MrDEq45aMg6iZlYdLomZmORXZdGlT4CBqZmXiy3kzs/wqpCs8B1EzK4PK6U/UQdTMysR1omZm+bkkamaW18b7Cd1UOIiaWXm4iZOZWU7Cl/NmZvn57ryZWSM5iJqZ5ec6UTOzvIRLomZmjVEhJVFF5B7krsWQ9C7wZrnz0YQ6AwvKnQlrsEr/3naJiB3ybChpDNnnU6wFETEoz7GaWkUE0UonacLGhou1lsffW+tQGZUSZmZl4iBqZtYIDqKbhhvKnQHLxd9bK+A6UTOzRnBJ1MysERxEzcwawUHUzKwRHEQ3EVL2eEf1a815a7kk9Sl3HqzpOIhuAiQpProD2KU6eEZEOJC2XMpUATdLGlnu/FjT8N35TYiki4ETgReAZRExosxZsiJI2gp4BJgWEReVOz9WWi6JbiIknQ6cCVwE9AN2LW+OrD4F1S9VEbECOAHYV9LvypszKzUH0Raqlsv0zYHvAEcDWwCXpfX2aeas2UbUqH7ZXdKeEbEcOAbo40BaWXw53wJJ2iwi1qT5C4B5QBvgZmBqRByWll0E9ACGRcQH5cqv1U7S14FBQDtgDDA8zT8MzImIs8uYPSsRl0RbGEl7AsMldUtJvYF3I+J+4PfATEn7SDof+DfgDgfQlkfSUOD4iDgamAJcTPbPbiXwGaCjpB3LmUcrDQfRlqcL2eX6VyR1JvuOOqVlNwIvAz8GjgO+GBEvlyWXtoFaql/eBC6UdDnQjSxwflHS9cC6iDghIt5p7nxa6flyvoUorEeT9ElgMLAG2Al4ErgHCKADMIfsh7i2PLm1QjW+u57A3IhYk5o33Q78KCImSfoV0BM4NyIWlzHLVkIOomWWSjCKiHU10j8OnEvWpKkKGAvsRlYqHRQR85s5q7YRkq4EPgUsAZ4CbgX+A9gdeB44Erg0Iip5FIZWx2Msld/WEbEMQNK/AduRlTJ/LGklsJzsZsR3I+I9SVumejUrsxol0GOAwRFxuKQngNURcZOku4GjyFpVfN0BtPK4JFpGkk4i++FdIOkK4BSyZky/Bv4ZEV+U1Bf4KjAb+E+yAOsvrcxqBNALgP3JSpvtgFOBkyJitaRdI2KmpHYRsaqMWbYm4iBaJpK2B/5MFiDXkgXPC4HLgU+Q1X+uiYgzJH0MWBQR88qVX6udpBOBzwHjgEvIvrMj07KrgL1T+lr/86tMDqJlImlb4E5gKVkQ/TbZU0g/jIiDJQ0ka1v4QEQMLV9OrS6SugNPA49GxJck3Qy8DbwEbAVcgVtQVDw3cSqTiHgfeIys6cv0grqyp9Pr7sAI4NoyZM+KEBFvkwXKwZKOA75OVu1yKnAoDqCtgkuiZSRpF2APsjrQ68k6qbgReIPsZsSnI2JG2TJoRZH0WeAHwLcj4oGUtrkfgmgdHERbAEkHkNWPfpusTWh3YGFEzCxrxqxoko4nG5juaxFxV7nzY83HQbSFkNQPeBy4JiI8SuQmKDVz+ldEvF7uvFjzcRBtQVJzppUR8a9y58XMiuMgambWCL47b2bWCA6iZmaN4CBqZtYIDqJmZo3gIGpm1ggOoq2MpA8lTZb0sqQ703C+efd1i6TPp/mbJPWpZ90jJB2S4xhvpB7+i0qvsc6yBh7re2lcJLOiOYi2Pisjon9E9AU+IBuCeT1JbfLsNCK+FBFT61nlCKDBQdSspXMQbd3+DuyRSol/lXQb8JKkNpL+W9Lzkl5MnUWjzK8lTZX0ENl4UKRl4yUNSPODJE2S9E9Jj0nqRRasv5ZKwZ+StIOku9Mxnk9DoiBpe0mPSnohDS1cc+yi/0fSfZImSpoi6cIay36S8vKYpB1S2u6SxqRt/i5p75J8mtYquWf7VkpSW+B4su72AAYCfVMHwhcCSyPiQElbAE9JepSs4+G9gH2BrsBUshFIC/e7A1knKoelfXWKiEWSfgssi4gfp/VuA34WEU+mcYnGAh8j67XqyYgYJukzZH2sbsz56RhbAs9LujsiFgJbA5Mi4ipJ3037vozsGfeLImK6pE+Qdf7y6Rwfo5mDaCu0paTJaf7vZGPZHwI8V9DhybHAftX1nWRDlvQGDgNuj4gPgTmSHq9l/wcBT1TvKyIW1ZGPo4E++miQzPapj9XDyLqSIyIeklTMgG6XSzolze+c8roQWEfWsQvAn4B7JG2TzvfOgmNvUcQxzGrlINr6rIyI/oUJKZgsL0wCvhIRY2usdwJZj/v1URHrQFaVdHDN8aJSXop+FlnSEWQB+eCIWCFpPNkQHbWJdNwlNT8Ds7xcJ2q1GQtcLGkzAEl7StoaeAIYkupMu5GNXlnT08DhknZN23ZK6e8D2xas9yjZpTVpvf5p9gng7JR2PNBxI3ndDlicAujeZCXhalVAdWn6LLJqgveAmZJOS8dQ6kHLLBcHUavNTWT1nZMkvQz8juyq5V5gOtnwF/8D/K3mhhHxLlk95j2S/slHl9MPAKdU31giG0tqQLpxNZWPWglcBxwmaRJZtcJbG8nrGKCtpBeB7wPPFCxbDuwjaSJZneewlH42cEHK3xRgcBGfiVmt3IuTmVkjuCRqZtYIDqJmZo3gIGpm1ggOomZmjeAgambWCA6iZmaN4CBqZtYI/weGuqxKpAkLrAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('LSTM')\n",
    "print ('val:')\n",
    "print_metrices(y_pred,y_test)\n",
    "\"\"\"\n",
    "    Transform the data from the excel sheet which are not under 'label' \n",
    "    column and apply predict with the final estimator.\n",
    "\n",
    "    This will be used later to print additional informations, like data types and memory used.\n",
    "\"\"\"\n",
    "create_confusion_matrix(confusion_matrix(y_test,y_pred),target_names=['fake','real'], normalize = False, \\\n",
    "                      title = 'Confusion matix of LSTM on val data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
